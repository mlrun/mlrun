{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Serving\n",
    "In this part we will user MLRun's **serving runtime** to deploy our trained models from the previous stage a `Voting Ensemble` using **max vote** logic.  \n",
    "We will also use MLRun's **Feature store** to receive the online **Feature Vector** we define in the previous stage.\n",
    "\n",
    "We will:\n",
    "- Define a model class to load our models, run preprocessing and predict on the data\n",
    "- Define Voting Ensemble function on top of our models\n",
    "- Test the serving function locally using our `mock server`\n",
    "- Deploy the function to the cluster and test it live\n",
    "\n",
    "<img src=\"../../_static/images/feature_store_demo_diagram.png\" width=\"600px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Since our work is done in a this project scope, we will first want to define the project itself for all our MLRun work in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "project, _ = mlrun.set_environment(project='fsdemo', user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Class\n",
    "- Load models\n",
    "- Predict from the FS Online service via the `patient_id` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudpickle import load\n",
    "import numpy as np\n",
    "import mlrun\n",
    "import os\n",
    "\n",
    "class ClassifierModel(mlrun.serving.V2ModelServer):\n",
    "    \n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "        model_file, extra_data = self.get_model('.pkl')\n",
    "        self.model = load(open(model_file, 'rb'))\n",
    "        \n",
    "        # Setup FS Online service\n",
    "        self.feature_service = mlrun.feature_store.get_online_feature_service('patient-deterioration')\n",
    "        \n",
    "        # Get feature vector statistics for imputing\n",
    "        self.feature_stats = self.feature_service.vector.get_stats_table()\n",
    "        \n",
    "    def preprocess(self, body: dict, op) -> list:\n",
    "        # Get patient feature vector \n",
    "        # from the patient_id given in the request\n",
    "        vectors = self.feature_service.get([{'patient_id': patient_id} for patient_id in body['inputs']])\n",
    "        \n",
    "        # Impute inf's in the data to the feature's mean value\n",
    "        # using the collected statistics from the Feature store\n",
    "        feature_vectors = []\n",
    "\n",
    "        for fv in vectors:\n",
    "            new_vec = []\n",
    "            for f, v in fv.items():\n",
    "                if np.isnan(v) or np.isinf(v):\n",
    "                    new_vec.append(self.feature_stats.loc[f, 'mean'])\n",
    "                else:\n",
    "                    new_vec.append(v)\n",
    "            feature_vectors.append(new_vec)\n",
    "            \n",
    "        # Set the final feature vector as our inputs\n",
    "        # to pass to the predict function\n",
    "        body['inputs'] = feature_vectors\n",
    "        return body\n",
    "\n",
    "    def predict(self, body: dict) -> list:\n",
    "        \"\"\"Generate model predictions from sample\"\"\"\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        result: np.ndarray = self.model.predict(feats)\n",
    "        return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Serving Function\n",
    "- Gather ClassifierModel code from this notebook\n",
    "- Define `VotingEnsemble` - Max-Vote based ensemble\n",
    "- Add downloaded models to the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"683pt\" height=\"196pt\"\n",
       " viewBox=\"0.00 0.00 682.73 196.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 192)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-192 678.7318,-192 678.7318,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"306.3905,-152.0493 308.541,-152.1479 310.6692,-152.2953 312.7665,-152.4913 314.8244,-152.7353 316.8346,-153.0266 318.7892,-153.3645 320.6806,-153.7479 322.5016,-154.1759 324.2454,-154.6472 325.9058,-155.1606 327.4769,-155.7147 328.9536,-156.308 330.3311,-156.9388 331.6055,-157.6054 332.7731,-158.3059 333.8311,-159.0385 334.7772,-159.8012 335.6098,-160.5918 336.3278,-161.4082 336.9308,-162.2481 337.4188,-163.1093 337.7925,-163.9894 338.0531,-164.886 338.2025,-165.7965 338.2426,-166.7186 338.1763,-167.6497 338.0065,-168.5873 337.7366,-169.5287 337.3705,-170.4713 336.912,-171.4127 336.3654,-172.3503 335.7353,-173.2814 335.026,-174.2035 334.2425,-175.114 333.3893,-176.0106 332.4714,-176.8907 331.4934,-177.7519 330.46,-178.5918 329.3758,-179.4082 328.2453,-180.1988 327.0729,-180.9615 325.8626,-181.6941 324.6184,-182.3946 323.3441,-183.0612 322.0431,-183.692 320.7187,-184.2853 319.3738,-184.8394 318.0113,-185.3528 316.6337,-185.8241 315.2432,-186.2521 313.8418,-186.6355 312.4315,-186.9734 311.0138,-187.2647 309.5901,-187.5087 308.1618,-187.7047 306.7301,-187.8521 305.296,-187.9507 303.8604,-188 302.4244,-188 300.9889,-187.9507 299.5548,-187.8521 298.1231,-187.7047 296.6948,-187.5087 295.2711,-187.2647 293.8534,-186.9734 292.4431,-186.6355 291.0417,-186.2521 289.6512,-185.8241 288.2735,-185.3528 286.9111,-184.8394 285.5662,-184.2853 284.2418,-183.692 282.9408,-183.0612 281.6665,-182.3946 280.4223,-181.6941 279.212,-180.9615 278.0396,-180.1988 276.9091,-179.4082 275.8249,-178.5918 274.7915,-177.7519 273.8135,-176.8907 272.8955,-176.0106 272.0424,-175.114 271.2588,-174.2035 270.5496,-173.2814 269.9195,-172.3503 269.3729,-171.4127 268.9144,-170.4713 268.5482,-169.5287 268.2784,-168.5873 268.1086,-167.6497 268.0423,-166.7186 268.0824,-165.7965 268.2318,-164.886 268.4924,-163.9894 268.8661,-163.1093 269.3541,-162.2481 269.9571,-161.4082 270.6751,-160.5918 271.5077,-159.8012 272.4538,-159.0385 273.5118,-158.3059 274.6794,-157.6054 275.9538,-156.9388 277.3313,-156.308 278.808,-155.7147 280.3791,-155.1606 282.0395,-154.6472 283.7833,-154.1759 285.6043,-153.7479 287.4957,-153.3645 289.4503,-153.0266 291.4605,-152.7353 293.5184,-152.4913 295.6157,-152.2953 297.7439,-152.1479 299.8944,-152.0493 302.0583,-152 304.2266,-152 306.3905,-152.0493\"/>\n",
       "<text text-anchor=\"middle\" x=\"303.1424\" y=\"-166.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n",
       "</g>\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title></title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"330.1424,-86.5442 330.1424,-101.4558 314.3262,-112 291.9587,-112 276.1424,-101.4558 276.1424,-86.5442 291.9587,-76 314.3262,-76 330.1424,-86.5442\"/>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"334.1424,-84.4034 334.1424,-103.5966 315.5373,-116 290.7476,-116 272.1424,-103.5966 272.1424,-84.4034 290.7476,-72 315.5373,-72 334.1424,-84.4034\"/>\n",
       "</g>\n",
       "<!-- _start&#45;&gt; -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M303.1424,-151.9891C303.1424,-144.291 303.1424,-135.0629 303.1424,-126.2561\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.6425,-126.2282 303.1424,-116.2282 299.6425,-126.2282 306.6425,-126.2282\"/>\n",
       "</g>\n",
       "<!-- 1&#45;patient_det_rf -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1&#45;patient_det_rf</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"85.1424\" cy=\"-18\" rx=\"85.2851\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"85.1424\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1&#45;patient_det_rf</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;1&#45;patient_det_rf -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>&#45;&gt;1&#45;patient_det_rf</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M273.2876,-83.5919C238.7769,-71.5606 181.301,-51.5232 138.9391,-36.7548\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.9277,-33.3929 129.3329,-33.4058 137.6233,-40.0028 139.9277,-33.3929\"/>\n",
       "</g>\n",
       "<!-- 2&#45;patient_det_xgboost -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2&#45;patient_det_xgboost</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"303.1424\" cy=\"-18\" rx=\"114.2798\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"303.1424\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2&#45;patient_det_xgboost</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;2&#45;patient_det_xgboost -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>&#45;&gt;2&#45;patient_det_xgboost</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M303.1424,-71.6086C303.1424,-63.7272 303.1424,-54.7616 303.1424,-46.4482\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.6425,-46.3974 303.1424,-36.3975 299.6425,-46.3975 306.6425,-46.3974\"/>\n",
       "</g>\n",
       "<!-- 3&#45;patient_det_adaboost -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3&#45;patient_det_adaboost</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"555.1424\" cy=\"-18\" rx=\"119.6788\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"555.1424\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3&#45;patient_det_adaboost</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;3&#45;patient_det_adaboost -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>&#45;&gt;3&#45;patient_det_adaboost</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M334.2953,-84.6047C373.4305,-72.802 441.541,-52.2608 491.8043,-37.102\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"493.0417,-40.3846 501.6052,-34.1462 491.0205,-33.6827 493.0417,-40.3846\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f124f768f10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the serving function from our code above\n",
    "fn = mlrun.code_to_function('patient-prediction', kind='serving', image=\"mlrun/mlrun\")\n",
    "\n",
    "# Set the Voting Ensemble as our router\n",
    "fn.set_topology('router', 'mlrun.serving.VotingEnsemble', name='PatientDeterioration')\n",
    "\n",
    "# Add the three previously trained models to the ensemble\n",
    "models_dir = os.path.abspath('models')\n",
    "for name in ['1-patient_det_rf', '2-patient_det_xgboost', '3-patient_det_adaboost']:\n",
    "    fn.add_model(name, class_name=\"ClassifierModel\", model_path=f\"store://artifacts/{project}/training_model:latest\")\n",
    "    \n",
    "# Plot the ensemble configuration\n",
    "fn.spec.graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the server locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-07-12 13:56:35,912 [info] model 1-patient_det_rf was loaded\n",
      "> 2021-07-12 13:56:36,061 [info] model 2-patient_det_xgboost was loaded\n",
      "> 2021-07-12 13:56:36,204 [info] model 3-patient_det_adaboost was loaded\n",
      "> 2021-07-12 13:56:36,205 [info] Loaded ['1-patient_det_rf', '2-patient_det_xgboost', '3-patient_det_adaboost']\n"
     ]
    }
   ],
   "source": [
    "# Create a mock server from the serving function\n",
    "server = fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the server locally with a sample id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '663f2cd58781492abf5db5dfef6dcca8',\n",
       " 'model_name': [1],\n",
       " 'outputs': [1],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = server.test('/v2/models/infer', body={'inputs': ['622-37-0180']})\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the function to the cluster (using Nuclio) and test it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-07-12 13:56:36,280 [info] Starting remote function deploy\n",
      "2021-07-12 13:56:36  (info) Deploying function\n",
      "2021-07-12 13:56:36  (info) Building\n",
      "2021-07-12 13:56:36  (info) Staging files and preparing base images\n",
      "2021-07-12 13:56:36  (info) Building processor image\n",
      "2021-07-12 13:56:38  (info) Build complete\n",
      "> 2021-07-12 13:56:45,964 [info] function deployed, address=default-tenant.app.dev65.lab.iguazeng.com:31657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://default-tenant.app.dev65.lab.iguazeng.com:31657'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable MLRun's model monitoring  \n",
    "fn.set_tracking()\n",
    "\n",
    "# Add the system mount to the function so\n",
    "# it will have access to our models\n",
    "fn.apply(mlrun.mount_v3io())\n",
    "\n",
    "# Deploy the function to the cluster\n",
    "fn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the function on the cluster using the `invoke` mechanism**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'd14a51ba-976d-446f-a83c-a2f2c08a4fee',\n",
       " 'model_name': [1],\n",
       " 'outputs': [1],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "fn.invoke('/v2/models/infer', body={'inputs': ['622-37-0180']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2b575b8a-454b-4904-a9e8-f60a96ac09ff',\n",
       " 'model_name': [1],\n",
       " 'outputs': [1],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "fn.invoke(path='/v2/models/infer', body=json.dumps({'inputs': ['622-37-0180']}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

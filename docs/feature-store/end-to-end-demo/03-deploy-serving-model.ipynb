{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Serving\n",
    "\n",
    "In this part you use MLRun's **serving runtime** to deploy the trained models from the previous stage a `Voting Ensemble` using **max vote** logic.  \n",
    "You will also use MLRun's **Feature store** to receive the latest tag of the online **Feature Vector** we defined in the previous stage.\n",
    "\n",
    "By the end of this tutorial youâ€™ll learn how to:\n",
    "- Define a model class to load the models, run preprocessing, and predict on the data\n",
    "- Define Voting Ensemble function on top of our models\n",
    "- Test the serving function locally using the `mock server`\n",
    "- Deploy the function to the cluster and test it live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "First, make sure SciKit-Learn is installed in the correct version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Restart your kernel post installing.\n",
    "Secondly, since the work is done in this project scope, define the project itself for all your MLRun work in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'fraud-demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-10-28 11:59:01,033 [info] loaded project fraud-demo from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "# Initialize the MLRun project object\n",
    "project = mlrun.get_or_create_project(project_name, context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model class\n",
    "- Load models\n",
    "- Predict from the FS Online service via the `source` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cloudpickle import load\n",
    "from mlrun.serving.v2_serving import V2ModelServer\n",
    "\n",
    "class ClassifierModel(V2ModelServer):\n",
    "    \n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "        model_file, extra_data = self.get_model('.pkl')\n",
    "        self.model = load(open(model_file, 'rb'))\n",
    "        \n",
    "    def predict(self, body: dict) -> list:\n",
    "        \"\"\"Generate model predictions from sample\"\"\"\n",
    "        print(f\"Input -> {body['inputs']}\")\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        result: np.ndarray = self.model.predict(feats)\n",
    "        return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a serving function\n",
    "\n",
    "MLRun serving can produce managed real-time serverless pipelines from various tasks, including MLRun models or standard model files.\n",
    "The pipelines use the Nuclio real-time serverless engine, which can be deployed anywhere.\n",
    "[Nuclio](https://nuclio.io/) is a high-performance open-source serverless framework that's focused on data, I/O, and compute-intensive workloads.\n",
    "\n",
    "The **EnrichmentVotingEnsemble** and the **EnrichmentModelRouter** router classes auto enrich the request with data from the feature store.\n",
    "The router input accepts lists of inference request (each request can be a dict or list of incoming features/keys). It enriches the request with data from the specified feature vector (`feature_vector_uri`).\n",
    "\n",
    "In many cases the features can have null values (None, NaN, Inf, ..). The `Enrichment` routers can substitute the null value with fixed or statistical value per feature. This is done through the `impute_policy` parameter, which accepts the impute policy per feature (where `*` is used to specify the default). The value can be a fixed number for constants or `$mean`, `$max`, `$min`, `$std`, `$count` for statistical values. to substitute the value with the equivalent feature stats (taken from the feature store).  \n",
    "\n",
    "The code below performs the following steps:\n",
    "\n",
    "- Gather ClassifierModel code from this notebook\n",
    "- Define `EnrichmentVotingEnsemble` - Max-Vote based ensemble with feature enrichment and imputing\n",
    "- Add the previously trained models to the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"763pt\" height=\"196pt\"\n",
       " viewBox=\"0.00 0.00 763.28 196.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 192)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-192 759.2803,-192 759.2803,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"404.0871,-152.0493 406.2376,-152.1479 408.3659,-152.2953 410.4632,-152.4913 412.5211,-152.7353 414.5313,-153.0266 416.4859,-153.3645 418.3773,-153.7479 420.1982,-154.1759 421.942,-154.6472 423.6024,-155.1606 425.1736,-155.7147 426.6502,-156.308 428.0278,-156.9388 429.3021,-157.6054 430.4697,-158.3059 431.5277,-159.0385 432.4739,-159.8012 433.3065,-160.5918 434.0245,-161.4082 434.6274,-162.2481 435.1154,-163.1093 435.4891,-163.9894 435.7498,-164.886 435.8991,-165.7965 435.9393,-166.7186 435.873,-167.6497 435.7032,-168.5873 435.4333,-169.5287 435.0671,-170.4713 434.6086,-171.4127 434.0621,-172.3503 433.4319,-173.2814 432.7227,-174.2035 431.9391,-175.114 431.086,-176.0106 430.168,-176.8907 429.19,-177.7519 428.1566,-178.5918 427.0724,-179.4082 425.942,-180.1988 424.7695,-180.9615 423.5592,-181.6941 422.3151,-182.3946 421.0407,-183.0612 419.7397,-183.692 418.4153,-184.2853 417.0705,-184.8394 415.708,-185.3528 414.3304,-185.8241 412.9398,-186.2521 411.5385,-186.6355 410.1281,-186.9734 408.7104,-187.2647 407.2868,-187.5087 405.8585,-187.7047 404.4268,-187.8521 402.9926,-187.9507 401.5571,-188 400.1211,-188 398.6856,-187.9507 397.2514,-187.8521 395.8197,-187.7047 394.3914,-187.5087 392.9678,-187.2647 391.5501,-186.9734 390.1397,-186.6355 388.7384,-186.2521 387.3478,-185.8241 385.9702,-185.3528 384.6077,-184.8394 383.2629,-184.2853 381.9385,-183.692 380.6375,-183.0612 379.3631,-182.3946 378.119,-181.6941 376.9087,-180.9615 375.7362,-180.1988 374.6058,-179.4082 373.5216,-178.5918 372.4882,-177.7519 371.5102,-176.8907 370.5922,-176.0106 369.7391,-175.114 368.9555,-174.2035 368.2463,-173.2814 367.6161,-172.3503 367.0696,-171.4127 366.6111,-170.4713 366.2449,-169.5287 365.975,-168.5873 365.8052,-167.6497 365.7389,-166.7186 365.7791,-165.7965 365.9284,-164.886 366.1891,-163.9894 366.5628,-163.1093 367.0508,-162.2481 367.6537,-161.4082 368.3717,-160.5918 369.2043,-159.8012 370.1505,-159.0385 371.2085,-158.3059 372.3761,-157.6054 373.6504,-156.9388 375.028,-156.308 376.5046,-155.7147 378.0758,-155.1606 379.7362,-154.6472 381.48,-154.1759 383.3009,-153.7479 385.1923,-153.3645 387.1469,-153.0266 389.1571,-152.7353 391.215,-152.4913 393.3123,-152.2953 395.4406,-152.1479 397.5911,-152.0493 399.7549,-152 401.9233,-152 404.0871,-152.0493\"/>\n",
       "<text text-anchor=\"middle\" x=\"400.8391\" y=\"-166.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n",
       "</g>\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title></title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"427.8391,-86.5442 427.8391,-101.4558 412.0229,-112 389.6553,-112 373.8391,-101.4558 373.8391,-86.5442 389.6553,-76 412.0229,-76 427.8391,-86.5442\"/>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"431.8391,-84.4034 431.8391,-103.5966 413.234,-116 388.4442,-116 369.8391,-103.5966 369.8391,-84.4034 388.4442,-72 413.234,-72 431.8391,-84.4034\"/>\n",
       "</g>\n",
       "<!-- _start&#45;&gt; -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M400.8391,-151.9891C400.8391,-144.291 400.8391,-135.0629 400.8391,-126.2561\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"404.3392,-126.2282 400.8391,-116.2282 397.3392,-126.2282 404.3392,-126.2282\"/>\n",
       "</g>\n",
       "<!-- RandomForestClassifier -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>RandomForestClassifier</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122.8391\" cy=\"-18\" rx=\"122.6784\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122.8391\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">RandomForestClassifier</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;RandomForestClassifier -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>&#45;&gt;RandomForestClassifier</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M369.7582,-85.5031C326.6973,-73.731 247.7558,-52.1499 190.7028,-36.5527\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.6011,-33.1699 181.032,-33.9089 189.7551,-39.9221 191.6011,-33.1699\"/>\n",
       "</g>\n",
       "<!-- GradientBoostingClassifier -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>GradientBoostingClassifier</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"400.8391\" cy=\"-18\" rx=\"137.2758\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"400.8391\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">GradientBoostingClassifier</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;GradientBoostingClassifier -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>&#45;&gt;GradientBoostingClassifier</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M400.8391,-71.6086C400.8391,-63.7272 400.8391,-54.7616 400.8391,-46.4482\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"404.3392,-46.3974 400.8391,-36.3975 397.3392,-46.3975 404.3392,-46.3974\"/>\n",
       "</g>\n",
       "<!-- AdaBoostClassifier -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>AdaBoostClassifier</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"655.8391\" cy=\"-18\" rx=\"99.3824\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"655.8391\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">AdaBoostClassifier</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;AdaBoostClassifier -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>&#45;&gt;AdaBoostClassifier</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M431.8522,-84.7569C472.0036,-72.7902 542.8987,-51.6607 594.1931,-36.3729\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"595.2692,-39.7044 603.853,-33.4939 593.2698,-32.996 595.2692,-39.7044\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f5af5d471d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the serving function from the code above\n",
    "serving_fn = mlrun.code_to_function('transaction-fraud', kind='serving', image=\"mlrun/mlrun\")\n",
    "\n",
    "serving_fn.set_topology('router', 'mlrun.serving.routers.EnrichmentVotingEnsemble', name='VotingEnsemble',\n",
    "                        feature_vector_uri=\"transactions-fraud-short\", impute_policy={\"*\": \"$mean\"})\n",
    "\n",
    "model_names = [\n",
    "'RandomForestClassifier',\n",
    "'GradientBoostingClassifier',\n",
    "'AdaBoostClassifier'\n",
    "]\n",
    "\n",
    "for i, name in enumerate(model_names, start=1):\n",
    "    serving_fn.add_model(name, class_name=\"ClassifierModel\", model_path=project.get_artifact_uri(f\"training_model#{i}:latest\"))\n",
    "\n",
    "# Plot the ensemble configuration\n",
    "serving_fn.spec.graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the server locally\n",
    "\n",
    "Before deploying the serving function, test it in the current notebook and check the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-10-28 11:59:11,260 [info] model RandomForestClassifier was loaded\n",
      "> 2021-10-28 11:59:11,306 [info] model GradientBoostingClassifier was loaded\n",
      "> 2021-10-28 11:59:11,350 [info] model AdaBoostClassifier was loaded\n"
     ]
    }
   ],
   "source": [
    "# Create a mock server from the serving function\n",
    "local_server = serving_fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input -> [[14.68, 14.68, 1.0, 14.68, 70.81]]\n",
      "Input -> [[14.68, 14.68, 1.0, 14.68, 70.81]]\n",
      "Input -> [[14.68, 14.68, 1.0, 14.68, 70.81]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '757c736c985a4c42b3ebd58f3c50f1b2',\n",
       " 'model_name': 'VotingEnsemble',\n",
       " 'outputs': [0],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose an id for the test\n",
    "sample_id = 'C76780537'\n",
    "\n",
    "model_inference_path = '/v2/models/infer'\n",
    "\n",
    "# Send our sample ID for prediction\n",
    "local_server.test(path=model_inference_path,\n",
    "            body={'inputs': [[sample_id]]})\n",
    "\n",
    "# Notice the input vector is printed 3 times (once per child model) and is enriched with data from the feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the real-time feature vector directly\n",
    "\n",
    "You can also directly query the feature store values using the `get_online_feature_service` method. This method is used internally in the EnrichmentVotingEnsemble router class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'amount_max_2h': 14.68,\n",
       "  'amount_max_12h': 70.81,\n",
       "  'amount_sum_2h': 14.68,\n",
       "  'amount_count_2h': 1.0,\n",
       "  'amount_avg_2h': 14.68}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Create the online feature service\n",
    "svc = fstore.get_online_feature_service('transactions-fraud-short:latest', impute_policy={\"*\": \"$mean\"})\n",
    "\n",
    "# Get sample feature vector\n",
    "sample_fv = svc.get([{'source': sample_id}])\n",
    "sample_fv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the function on the kubernetes cluster\n",
    "\n",
    "You can now deploy the function. Once it's deployed you get a function with an http trigger that can be called from other locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-10-28 11:59:17,554 [info] Starting remote function deploy\n",
      "2021-10-28 11:59:17  (info) Deploying function\n",
      "2021-10-28 11:59:17  (info) Building\n",
      "2021-10-28 11:59:17  (info) Staging files and preparing base images\n",
      "2021-10-28 11:59:17  (info) Building processor image\n",
      "2021-10-28 11:59:19  (info) Build complete\n",
      "2021-10-28 11:59:25  (info) Function deploy complete\n",
      "> 2021-10-28 11:59:25,657 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-fraud-demo-admin-transaction-fraud.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['default-tenant.app.yh38.iguazio-cd2.com:32287']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://default-tenant.app.yh38.iguazio-cd2.com:32287'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Enable model monitoring\n",
    "serving_fn.set_tracking()\n",
    "project.set_model_monitoring_credentials(os.getenv('V3IO_ACCESS_KEY'))\n",
    "\n",
    "# Deploy the serving function\n",
    "serving_fn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the server\n",
    "\n",
    "Test the serving function and examine the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-10-28 11:59:25,722 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-fraud-demo-admin-transaction-fraud.default-tenant.svc.cluster.local:8080/v2/models/infer'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '4b9c4914-964f-4bd5-903d-c4885ed7c090',\n",
       " 'model_name': 'VotingEnsemble',\n",
       " 'outputs': [0],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose an id for the test\n",
    "sample_id = 'C76780537'\n",
    "\n",
    "model_inference_path = '/v2/models/infer'\n",
    "\n",
    "# Send the sample ID for prediction\n",
    "serving_fn.invoke(path=model_inference_path,\n",
    "                  body={'inputs': [[sample_id]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also directly query the feature store values, which are used in the enrichment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate incoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = mlrun.get_dataitem('https://s3.wasabisys.com/iguazio/data/fraud-demo-mlrun-fs-docs/data.csv').as_df()\n",
    "\n",
    "# Sample 50k lines\n",
    "data = data.sample(50000)\n",
    "\n",
    "# keys\n",
    "sample_ids = data['source'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-10-28 12:00:23,079 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-fraud-demo-admin-transaction-fraud.default-tenant.svc.cluster.local:8080/v2/models/infer'}\n",
      "{'id': '6b813638-e9ef-4e92-85c8-cfbd0b74fe32', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2021-10-28 12:00:23,857 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-fraud-demo-admin-transaction-fraud.default-tenant.svc.cluster.local:8080/v2/models/infer'}\n",
      "{'id': 'f84bf2ec-a718-4e90-a7d5-fe08e254f3c8', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2021-10-28 12:00:24,545 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-fraud-demo-admin-transaction-fraud.default-tenant.svc.cluster.local:8080/v2/models/infer'}\n",
      "{'id': '7bb023f7-edbc-47a6-937b-4a15c8380b74', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2021-10-28 12:00:24,921 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-fraud-demo-admin-transaction-fraud.default-tenant.svc.cluster.local:8080/v2/models/infer'}\n",
      "{'id': '57882cca-537a-43e1-9986-1bbc72fb84b7', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n"
     ]
    }
   ],
   "source": [
    "from random import choice, uniform\n",
    "from time import sleep\n",
    "\n",
    "# Sending random requests\n",
    "for _ in range(4000):\n",
    "    data_point = choice(sample_ids)\n",
    "    try:\n",
    "        resp = serving_fn.invoke(path=model_inference_path, body={'inputs': [[data_point]]})\n",
    "        print(resp)\n",
    "        sleep(uniform(0.2, 1.7))\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Original NYC Taxi ML Notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /conda/lib/python3.7/site-packages (2.3.0)\n",
      "Requirement already satisfied: shapely in /User/.pythonlibs/jupyter2/lib/python3.7/site-packages (1.7.1)\n",
      "Requirement already satisfied: scipy in /conda/lib/python3.7/site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: numpy in /conda/lib/python3.7/site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn in /conda/lib/python3.7/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /conda/lib/python3.7/site-packages (from scikit-learn->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /conda/lib/python3.7/site-packages (from scikit-learn->lightgbm) (0.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import scipy as scipy\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgbm\n",
    "import os\n",
    "import gc\n",
    "import shapely.wkt\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    return df[(df.fare_amount > 0)  & (df.fare_amount <= 500) &\n",
    "             (df.PULocationID > 0) & (df.PULocationID <= 263) & \n",
    "             (df.DOLocationID > 0) & (df.DOLocationID <= 263)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radian_conv(degree):\n",
    "    \"\"\"\n",
    "    Return radian.\n",
    "    \"\"\"\n",
    "    return  np.radians(degree)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Compute Haversine distance\n",
    "def sphere_dist(pickup_lat, pickup_lon, dropoff_lat, dropoff_lon):\n",
    "    \"\"\"\n",
    "    Return distance along great radius between pickup and dropoff coordinates.\n",
    "    \"\"\"\n",
    "    #Define earth radius (km)\n",
    "    R_earth = 6371\n",
    "    #Convert degrees to radians\n",
    "    pickup_lat, pickup_lon, dropoff_lat, dropoff_lon = map(np.radians,\n",
    "                                                             [pickup_lat, pickup_lon, \n",
    "                                                              dropoff_lat, dropoff_lon])\n",
    "    #Compute distances along lat, lon dimensions\n",
    "    dlat = dropoff_lat - pickup_lat\n",
    "    dlon = dropoff_lon - pickup_lon\n",
    "    \n",
    "    #Compute haversine distance\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(pickup_lat) * np.cos(dropoff_lat) * np.sin(dlon/2.0)**2\n",
    "    return 2 * R_earth * np.arcsin(np.sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_airport_dist(dataset):\n",
    "    \"\"\"\n",
    "    Return minimum distance from pickup or dropoff coordinates to each airport.\n",
    "    JFK: John F. Kennedy International Airport\n",
    "    EWR: Newark Liberty International Airport\n",
    "    LGA: LaGuardia Airport\n",
    "    SOL: Statue of Liberty \n",
    "    NYC: Newyork Central\n",
    "    \"\"\"\n",
    "    jfk_coord = (40.639722, -73.778889)\n",
    "    ewr_coord = (40.6925, -74.168611)\n",
    "    lga_coord = (40.77725, -73.872611)\n",
    "    sol_coord = (40.6892,-74.0445) # Statue of Liberty\n",
    "    nyc_coord = (40.7141667,-74.0063889) \n",
    "    \n",
    "    \n",
    "    pickup_lat = dataset['pickup_latitude']\n",
    "    dropoff_lat = dataset['dropoff_latitude']\n",
    "    pickup_lon = dataset['pickup_longitude']\n",
    "    dropoff_lon = dataset['dropoff_longitude']\n",
    "    \n",
    "    pickup_jfk = sphere_dist(pickup_lat, pickup_lon, jfk_coord[0], jfk_coord[1]) \n",
    "    dropoff_jfk = sphere_dist(jfk_coord[0], jfk_coord[1], dropoff_lat, dropoff_lon) \n",
    "    pickup_ewr = sphere_dist(pickup_lat, pickup_lon, ewr_coord[0], ewr_coord[1])\n",
    "    dropoff_ewr = sphere_dist(ewr_coord[0], ewr_coord[1], dropoff_lat, dropoff_lon) \n",
    "    pickup_lga = sphere_dist(pickup_lat, pickup_lon, lga_coord[0], lga_coord[1]) \n",
    "    dropoff_lga = sphere_dist(lga_coord[0], lga_coord[1], dropoff_lat, dropoff_lon)\n",
    "    pickup_sol = sphere_dist(pickup_lat, pickup_lon, sol_coord[0], sol_coord[1]) \n",
    "    dropoff_sol = sphere_dist(sol_coord[0], sol_coord[1], dropoff_lat, dropoff_lon)\n",
    "    pickup_nyc = sphere_dist(pickup_lat, pickup_lon, nyc_coord[0], nyc_coord[1]) \n",
    "    dropoff_nyc = sphere_dist(nyc_coord[0], nyc_coord[1], dropoff_lat, dropoff_lon)\n",
    "    \n",
    "    \n",
    "    \n",
    "    dataset['jfk_dist'] = pickup_jfk + dropoff_jfk\n",
    "    dataset['ewr_dist'] = pickup_ewr + dropoff_ewr\n",
    "    dataset['lga_dist'] = pickup_lga + dropoff_lga\n",
    "    dataset['sol_dist'] = pickup_sol + dropoff_sol\n",
    "    dataset['nyc_dist'] = pickup_nyc + dropoff_nyc\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_info(dataset):\n",
    "    #Convert to datetime format\n",
    "    dataset['pickup_datetime'] = pd.to_datetime(dataset['tpep_pickup_datetime'],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    dataset['hour'] = dataset.pickup_datetime.dt.hour\n",
    "    dataset['day'] = dataset.pickup_datetime.dt.day\n",
    "    dataset['month'] = dataset.pickup_datetime.dt.month\n",
    "    dataset['weekday'] = dataset.pickup_datetime.dt.weekday\n",
    "    dataset['year'] = dataset.pickup_datetime.dt.year\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zones_dict(zones_url):\n",
    "    zones_df = pd.read_csv(zones_url)\n",
    "    \n",
    "    # Remove unnecessary fields\n",
    "    zones_df.drop(['Shape_Leng', 'Shape_Area', 'zone', 'LocationID', 'borough'], axis=1, inplace=True)\n",
    "    \n",
    "    # Convert DF to dictionary\n",
    "    zones_dict = zones_df.set_index('OBJECTID').to_dict('index')\n",
    "    \n",
    "    # Add lat/long to each zone\n",
    "    for zone in zones_dict:\n",
    "        shape = shapely.wkt.loads(zones_dict[zone]['the_geom'])\n",
    "        zones_dict[zone]['long'] = shape.centroid.x\n",
    "        zones_dict[zone]['lat'] = shape.centroid.y\n",
    "    \n",
    "    return zones_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zone_lat(zones_dict, zone_id):\n",
    "    return zones_dict[zone_id]['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zone_long(zones_dict, zone_id):\n",
    "    return zones_dict[zone_id]['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_dict = get_zones_dict('https://s3.wasabisys.com/iguazio/data/Taxi/taxi_zones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = pd.read_csv('https://s3.wasabisys.com/iguazio/data/Taxi/yellow_tripdata_2019-01_subset.csv')\n",
    "new_train_df = clean_df(new_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can take a minute or two\n",
    "new_train_df['pickup_latitude'] = new_train_df.apply(lambda x: get_zone_lat(zones_dict, x['PULocationID']), axis=1 )\n",
    "new_train_df['pickup_longitude'] = new_train_df.apply(lambda x: get_zone_long(zones_dict, x['PULocationID']), axis=1 )\n",
    "new_train_df['dropoff_latitude'] = new_train_df.apply(lambda x: get_zone_lat(zones_dict, x['DOLocationID']), axis=1 )\n",
    "new_train_df['dropoff_longitude'] = new_train_df.apply(lambda x: get_zone_long(zones_dict, x['DOLocationID']), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = add_datetime_info(new_train_df)\n",
    "new_train_df = add_airport_dist(new_train_df)\n",
    "\n",
    "new_train_df['pickup_latitude'] = radian_conv(new_train_df['pickup_latitude'])\n",
    "new_train_df['pickup_longitude'] = radian_conv(new_train_df['pickup_longitude'])\n",
    "new_train_df['dropoff_latitude'] = radian_conv(new_train_df['dropoff_latitude'])\n",
    "new_train_df['dropoff_longitude'] = radian_conv(new_train_df['dropoff_longitude'])\n",
    "\n",
    "y = new_train_df['fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary fields\n",
    "new_train_df.drop(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'congestion_surcharge', 'improvement_surcharge', 'pickup_datetime',\n",
    "                  'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'total_amount', 'RatecodeID', 'store_and_fwd_flag',\n",
    "                  'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount'], \n",
    "                  axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(new_train_df,y,random_state=123,test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del new_train_df\n",
    "del y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'nthread': 4,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': -1,\n",
    "        'subsample': 0.8,\n",
    "        'bagging_fraction' : 1,\n",
    "        'max_bin' : 5000 ,\n",
    "        'bagging_freq': 20,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'metric': 'rmse',\n",
    "        'min_split_gain': 0.5,\n",
    "        'min_child_weight': 1,\n",
    "        'min_child_samples': 10,\n",
    "        'scale_pos_weight':1,\n",
    "        'zero_as_missing': True,\n",
    "        'seed':0,\n",
    "        'num_rounds':50000\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/conda/lib/python3.7/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's rmse: 3.01588\n",
      "[1000]\tvalid_0's rmse: 2.9836\n",
      "[1500]\tvalid_0's rmse: 2.97776\n",
      "[2000]\tvalid_0's rmse: 2.98137\n",
      "Early stopping, best iteration is:\n",
      "[1615]\tvalid_0's rmse: 2.97663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "732"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = lgbm.Dataset(x_train, y_train, silent=False,categorical_feature=['year','month','day','weekday'])\n",
    "valid_set = lgbm.Dataset(x_test, y_test, silent=False,categorical_feature=['year','month','day','weekday'])\n",
    "model = lgbm.train(params, train_set = train_set, num_boost_round=10000,early_stopping_rounds=500,verbose_eval=500, valid_sets=valid_set)\n",
    "del x_train\n",
    "del y_train\n",
    "del x_test\n",
    "del y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = StringIO(\"\"\"\n",
    "passenger_count,trip_distance,pickup_latitude,pickup_longitude,dropoff_latitude,dropoff_longitude,hour,day,month,weekday,year,jfk_dist,ewr_dist,lga_dist,sol_dist,nyc_dist\n",
    "1,0.80,0.711950,-1.291073,0.712059,1.290988,13,1,1,1,2019,47.274013,40.386065,16.975747,26.587155,18.925788\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_data, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>jfk_dist</th>\n",
       "      <th>ewr_dist</th>\n",
       "      <th>lga_dist</th>\n",
       "      <th>sol_dist</th>\n",
       "      <th>nyc_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.71195</td>\n",
       "      <td>-1.291073</td>\n",
       "      <td>0.712059</td>\n",
       "      <td>1.290988</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>47.274013</td>\n",
       "      <td>40.386065</td>\n",
       "      <td>16.975747</td>\n",
       "      <td>26.587155</td>\n",
       "      <td>18.925788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  trip_distance  pickup_latitude  pickup_longitude  \\\n",
       "0                1            0.8          0.71195         -1.291073   \n",
       "\n",
       "   dropoff_latitude  dropoff_longitude  hour  day  month  weekday  year  \\\n",
       "0          0.712059           1.290988    13    1      1        1  2019   \n",
       "\n",
       "    jfk_dist   ewr_dist   lga_dist   sol_dist   nyc_dist  \n",
       "0  47.274013  40.386065  16.975747  26.587155  18.925788  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.53629134]\n"
     ]
    }
   ],
   "source": [
    "#Predict from test set\n",
    "prediction = model.predict(test_df, num_iteration = model.best_iteration)      \n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

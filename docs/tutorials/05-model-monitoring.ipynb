{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(realtime-monitor-drift-tutor)=\n",
    "# Model monitoring\n",
    "\n",
    "This tutorial illustrates the basic model monitoring capabilities of MLRun: deploying a model to a live endpoint and calculating data drift.\n",
    "\n",
    "In this tutorial:\n",
    "- [Prerequisites](#prerequisites)\n",
    "- [Invoke the model](#invoke-the-model)\n",
    "- [Register and deploy the model-monitoring app](#register-and-deploy-the-model-monitoring-app)\n",
    "- [Invoke the model again](#invoke-the-model-again)\n",
    "- [View model monitoring artifacts and drift in the UI](#view-model-monitoring-artifacts-and-drift-in-the-ui)\n",
    "- [View model monitoring artifacts and drift in Grafana](#view-model-monitoring-artifacts-and-drift-in-grafana)\n",
    "- [Batch infer model-monitoring](#batch-infer-model-monitoring)\n",
    "\n",
    "See also\n",
    "- - {ref}`monitoring-models`\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Enable model monitoring on the project\n",
    "\n",
    "Enable model monitoring for a project with {py:meth}`~mlrun.projects.MlrunProject.enable_model_monitoring`.\n",
    "The controller runs, by default, every 10 minutes, which is also the minimum interval. \n",
    "You can modify the frequency with the parameter `base_period`. \n",
    "To change the `base_period`, call `update_model_monitoring_controller`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-20 08:49:27,495 [info] Project loaded successfully: {\"project_name\":\"tutorial\"}\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "project_name = \"tutorial\"\n",
    "project = mlrun.get_or_create_project(project_name, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-20 08:49:27,599 [warning] enable_model_monitoring: 'base_period' < 10 minutes is not supported in production environments: {\"project\":\"tutorial\"}\n"
     ]
    }
   ],
   "source": [
    "project.set_model_monitoring_credentials(None, \"v3io\", \"v3io\", \"v3io\")\n",
    "project.enable_model_monitoring(base_period=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log the model with training data\n",
    "\n",
    "See the parameter descriptions in {py:meth}`~mlrun.projects.MlrunProject.log_model`. \n",
    "{Download the pickle file}`pickle file <./src/model2.pkl>` used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the training set\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv(\n",
    "    \"https://s3.us-east-1.wasabisys.com/iguazio/data/iris/iris_dataset.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.artifacts.model.ModelArtifact at 0x7f83dbbdbbe0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"RandomForestClassifier\"\n",
    "project.log_model(\n",
    "    model_name,\n",
    "    model_file=\"model2.pkl\",\n",
    "    training_set=train_set,\n",
    "    framework=\"sklearn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import, enable monitoring, and deploy the serving function\n",
    "\n",
    "Use the [v2_model_server serving](https://www.mlrun.org/hub/functions/master/v2-model-server/) function \n",
    "from the MLRun function hub.\n",
    "\n",
    "Add the model to the serving function's routing spec ({py:meth}`~mlrun.runtimes.ServingRuntime.add_model`), \n",
    "enable monitoring on the serving function ({py:meth}`~mlrun.runtimes.ServingRuntime.set_tracking`),\n",
    "and then deploy the function ({py:meth}`~mlrun.projects.MlrunProject.deploy_function`).\n",
    "\n",
    "The result of this step is that the model-monitoring stream pod writes data to Parquet, by model endpoint. \n",
    "Every base period, the controller checks for new data and if it finds, sends it to the relevant app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-20 08:49:30,631 [info] Starting remote function deploy\n",
      "2024-10-20 08:49:30  (info) Deploying function\n",
      "2024-10-20 08:49:30  (info) Building\n",
      "2024-10-20 08:49:31  (info) Staging files and preparing base images\n",
      "2024-10-20 08:49:31  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2024-10-20 08:49:31  (info) Building processor image\n",
      "2024-10-20 08:50:36  (info) Build complete\n",
      "2024-10-20 08:50:44  (info) Function deploy complete\n",
      "> 2024-10-20 08:50:51,999 [info] Successfully deployed function: {\"external_invocation_urls\":[\"tutorial-serving.default-tenant.app.vmdev94.lab.iguazeng.com/\"],\"internal_invocation_urls\":[\"nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080\"]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeployStatus(state=ready, outputs={'endpoint': 'http://tutorial-serving.default-tenant.app.vmdev94.lab.iguazeng.com/', 'name': 'tutorial-serving'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the serving function\n",
    "serving_fn = mlrun.import_function(\n",
    "    \"hub://v2_model_server\", project=project_name, new_name=\"serving\"\n",
    ")\n",
    "\n",
    "serving_fn.add_model(\n",
    "    model_name, model_path=f\"store://models/tutorial/RandomForestClassifier:latest\"\n",
    ")\n",
    "\n",
    "# enable monitoring on this serving function\n",
    "serving_fn.set_tracking()\n",
    "\n",
    "serving_fn.spec.build.requirements = [\"scikit-learn==1.0.2\"]\n",
    "\n",
    "# Deploy the serving function\n",
    "project.deploy_function(serving_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the model\n",
    "\n",
    "Invoke the model function with {py:meth}`~mlrun.runtimes.RemoteRuntime.invoke`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-20 08:50:53,016 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 08:50:53,546 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 08:50:53,595 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 08:50:53,645 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 08:50:53,730 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 08:50:53,783 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 08:50:53,835 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from random import choice\n",
    "\n",
    "iris_data = pd.read_csv(\n",
    "    \"https://s3.us-east-1.wasabisys.com/iguazio/data/iris/iris_to_predict.csv\"\n",
    ")\n",
    "iris_data = iris_data.to_numpy().tolist()\n",
    "\n",
    "model_name = \"RandomForestClassifier\"\n",
    "serving_1 = project.get_function(\"serving\")\n",
    "0\n",
    "for i in range(1000):\n",
    "    data_point = choice(iris_data)\n",
    "    serving_1.invoke(\n",
    "        f\"v2/models/{model_name}/infer\", json.dumps({\"inputs\": [data_point]})\n",
    "    )\n",
    "    sleep(choice([0.01, 0.04]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After invoking the model, you can see the model endpoints and minimal meta data (for example, \n",
    "last prediction) in the **Models | Model Endpoints** page.\n",
    "\n",
    "<img src=\"../tutorials/_static/images/model_endpoint_1.png\" width=\"1300\" >\n",
    "\n",
    "You can also see the basic statistics in Grafana.\n",
    "\n",
    "(register-model-monitoring-app)=\n",
    "## Register and deploy the model monitoring app\n",
    "The next step is to deploy the model-monitoring job to generate the full meta data. \n",
    "Add the monitoring function to the project using {py:meth}`~mlrun.projects.MlrunProject.set_model_monitoring_function`. \n",
    "Then, deploy the function using {py:meth}`~mlrun.projects.MlrunProject.deploy_function`.\n",
    "\n",
    "This tutorial illustrates two monitoring apps:\n",
    "- The first is the default monitoring app.\n",
    "- The second integrates [Evidently](https://github.com/evidentlyai/evidently) as an MLRun function to create MLRun artifacts.\n",
    "\n",
    "Learn how to write your own app in {ref}`mm-applications`.\n",
    "\n",
    "After deploying the jobs they show in the UI under Real-time functions (Nuclio).\n",
    "\n",
    "### Default monitoring app\n",
    "\n",
    "First download the {download}`demo_app <./src/demo_app.py>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-20 08:51:56,847 [info] Starting remote function deploy\n",
      "2024-10-20 08:51:57  (info) Deploying function\n",
      "2024-10-20 08:51:57  (info) Building\n",
      "2024-10-20 08:51:57  (info) Staging files and preparing base images\n",
      "2024-10-20 08:51:57  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2024-10-20 08:51:57  (info) Building processor image\n",
      "2024-10-20 08:53:43  (info) Build complete\n",
      "2024-10-20 08:54:01  (info) Function deploy complete\n",
      "> 2024-10-20 08:54:09,038 [info] Successfully deployed function: {\"external_invocation_urls\":[],\"internal_invocation_urls\":[\"nuclio-tutorial-myapp.default-tenant.svc.cluster.local:8080\"]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeployStatus(state=ready, outputs={'endpoint': 'http://nuclio-tutorial-myapp.default-tenant.svc.cluster.local:8080', 'name': 'tutorial-myapp'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_app = project.set_model_monitoring_function(\n",
    "    func=\"src/demo_app.py\",\n",
    "    application_class=\"DemoMonitoringApp\",\n",
    "    name=\"myApp\",\n",
    ")\n",
    "\n",
    "project.deploy_function(my_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evidently app\n",
    "You can use the MLRun built-in class, `EvidentlyModelMonitoringApplicationBase`, to integrate [Evidently](https://github.com/evidentlyai/evidently) as an MLRun function and create MLRun artifacts.\n",
    "\n",
    "First download the {download}`evidently_app <./src/evidently_app.py>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-20 08:54:09,190 [info] Starting remote function deploy\n",
      "2024-10-20 08:54:09  (info) Deploying function\n",
      "2024-10-20 08:54:09  (info) Building\n",
      "2024-10-20 08:54:09  (info) Staging files and preparing base images\n",
      "2024-10-20 08:54:09  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2024-10-20 08:54:09  (info) Building processor image\n",
      "2024-10-20 08:56:34  (info) Build complete\n",
      "2024-10-20 08:56:57  (info) Function deploy complete\n",
      "> 2024-10-20 08:57:01,573 [info] Successfully deployed function: {\"external_invocation_urls\":[],\"internal_invocation_urls\":[\"nuclio-tutorial-myevidentlyapp.default-tenant.svc.cluster.local:8080\"]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeployStatus(state=ready, outputs={'endpoint': 'http://nuclio-tutorial-myevidentlyapp.default-tenant.svc.cluster.local:8080', 'name': 'tutorial-myevidentlyapp'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register the second app named \"evidently_app\"\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "my_evidently_app = project.set_model_monitoring_function(\n",
    "    func=\"src/evidently_app.py\",\n",
    "    image=\"mlrun/mlrun\",\n",
    "    requirements=[\n",
    "        \"evidently~=0.4.32\",\n",
    "    ],\n",
    "    name=\"MyEvidentlyApp\",\n",
    "    application_class=\"DemoEvidentlyMonitoringApp\",\n",
    "    evidently_workspace_path=os.path.abspath(\n",
    "        f\"/v3io/projects/set_model_monitoring_function/artifacts/evidently_workspace\"\n",
    "    ),\n",
    "    evidently_project_id=str(uuid.uuid4()),\n",
    ")\n",
    "\n",
    "project.deploy_function(my_evidently_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the model again\n",
    "\n",
    "The controller checks for new datasets every `base_period` to send to the app. Invoking the model a second time ensures that the previous \n",
    "window closed and therefore the data contains the full monitoring window. The controller checks the Parquet DB every 10 minutes \n",
    "(or higher number, user-configurable), and streams any new data to the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-20 09:14:40,877 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 09:14:41,426 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 09:14:41,471 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 09:14:41,545 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 09:14:41,590 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n",
      "> 2024-10-20 09:14:41,664 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer\"}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"RandomForestClassifier\"\n",
    "serving_1 = project.get_function(\"serving\")\n",
    "\n",
    "for i in range(150):\n",
    "    data_point = choice(iris_data)\n",
    "    serving_1.invoke(\n",
    "        f\"v2/models/RandomForestClassifier/infer\", json.dumps({\"inputs\": [data_point]})\n",
    "    )\n",
    "    sleep(choice([0.01, 0.04]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View model monitoring artifacts and drift in the UI\n",
    "\n",
    "Now you can view the application results. \n",
    "\n",
    "<img src=\"../tutorials/_static/images/mm-myapp.png\" width=\"1000\" >\n",
    "\n",
    "And if you've used Evidently:\n",
    "\n",
    "<img src=\"./_static/images/mm-logger-dashb-evidently.png\" >\n",
    "\n",
    "And an example from the various graphs:\n",
    "\n",
    "<img src=\"./_static/images/mm-evidently.png\" >\n",
    "\n",
    "For more information on the UI, see [Model monitoring using the platform UI](../model-monitoring/monitoring-models.html)\n",
    "\n",
    "## View model monitoring artifacts and drift in Grafana\n",
    " \n",
    "Monitoring details:\n",
    "\n",
    "![grafana_dashboard_2](../tutorials/_static/images/grafana_dashboard_2.png)\n",
    "\n",
    "And drift and operational metrics over time:\n",
    "\n",
    "![grafana_dashboard_3](../tutorials/_static/images/grafana_dashboard_3.png)\n",
    "\n",
    "All of the Grafana dashboards are described in {ref}`monitoring-models-grafana`.\n",
    "\n",
    "## Batch infer model-monitoring\n",
    "\n",
    "You can use the batch function (stored in the [function hub](https://www.mlrun.org/hub/functions/master/batch_inference_2/))\n",
    "to evaluate data against your logged model **without disturbing the model**, for example a one-time evaluation of new data.  \n",
    "\n",
    "See more in {ref}`batch_inference_overview` and {ref}`batch-infer-drift-tutor`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

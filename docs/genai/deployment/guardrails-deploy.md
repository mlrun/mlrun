(guardrails-deploy)=
# Guardrails for deployment

When productizing GenAI applications, significant engineering efforts should be allocated to test and protect against various LLM risks. Guardrails should include measures that:
- Safeguarding user privacy
- Protecting the intellectual property rights and the data in the LLMs.
- Aligning LLM functionalities with various legal and regulatory standards to avoid regulatory non-compliance.
- Ensuring outputs are unbiased and fair, avoiding perpetuation of stereotypes or discriminatory practices.
- Prevent toxicity: Filtering out and preventing the generation of harmful or offensive content.
- Prevent the exploitation of LLMs for unethical or malicious purposes.
- Prevent hallucination: Minimizing the risk of LLMs generating factually incorrect or misleading information.
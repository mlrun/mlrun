{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Serving an ML Model\n",
    "\n",
    "This part of the MLRun getting-started tutorial walks you through the steps for creating, deploying, and testing a model-serving function (\"a serving function\" a.k.a. \"a model server\") using MLRun and Nuclio.\n",
    "\n",
    "MlRun serving can take MLRun models or standard model files and produce managed real-time serverless functions based on the Nuclio real-time serverless engine, which can be deployed everywhere\n",
    "[Nuclio](https://nuclio.io/) is a high-performance open-source \"serverless\" framework that's focused on data, I/O, and compute-intensive workloads.\n",
    "For more information, see the [Nuclio GitHub repository](https://github.com/nuclio/nuclio).\n",
    "\n",
    "Simple model serving classes can be written in Python or be taken from a set of pre-developed ML/DL classes.\n",
    "The code can handle complex data, feature preparation, and binary data (such as images and video files).\n",
    "The Nuclio serving engine supports the full model-serving life cycle, including auto generation of microservices, APIs, load balancing, model logging and monitoring, and configuration management.\n",
    "\n",
    "The tutorial consists of the following steps:\n",
    "\n",
    "1. [Setup](#gs-tutorial-3-step-setup) &mdash; load your project\n",
    "2. [Writing A Simple Serving Class](#gs-tutorial-3-step-writing-a-serving-class)\n",
    "3. [Deploying the Model-Serving Function (Service)](#gs-tutorial-3-step-deploy-the-serving-function)\n",
    "4. [Using the Model-Serving Function](#gs-tutorial-3-step-using-the-serving-function)\n",
    "5. [Viewing the Nuclio Serving Function on the Dashboard](#gs-tutorial-3-step-view-serving-func-in-ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-prerequisites\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "The following steps are a continuation of the previous parts of this getting-started tutorial and rely on the generated outputs.\n",
    "Therefore, make sure to first run parts 1&mdash;[2](02-model-training.ipynb) of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-step-setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-import-libaries\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-01-24 19:11:18,203 [warning] Failed resolving version info. Ignoring and using defaults\n",
      "> 2021-01-24 19:11:19,459 [warning] Unable to parse server or client version. Assuming compatible: {'server_version': '0.6.0-rc10', 'client_version': 'unstable'}\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "import mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Your MLRun Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `set_environment` MLRun method to configure the working environment and default configuration. \n",
    "Define a project name and set the `project` parameter, setting the `user_project` flag will add the current user to the project name (avoiding a case of multiple users using the same project name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project name\n",
    "project_name_base = 'getting-started-tutorial'\n",
    "# Initialize your MLRun environment and save the artifacts path\n",
    "project_name, artifact_path = mlrun.set_environment(project=project_name_base, user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-step-writing-a-serving-class\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Writing A Simple Serving Class\n",
    "\n",
    "The serving class is initialized automatically by the model server.\n",
    "All you need is to implement two mandatory methods:\n",
    "\n",
    "- `load` &mdash; downloads the model files and loads the model into memory.\n",
    "    This can be done either synchronously or asynchronously.\n",
    "- `predict` &mdash; accepts a request payload and returns prediction (inference) results.\n",
    "\n",
    "For more detailed information on serving classes, see the [MLRun documentation](https://github.com/mlrun/mlrun/blob/release/v0.6.x-latest/mlrun/serving/README.md).\n",
    "\n",
    "The following code demonstrates a minimal scikit-learn (a.k.a. sklearn) serving-class implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudpickle import load\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import mlrun\n",
    "\n",
    "class ClassifierModel(mlrun.serving.V2ModelServer):\n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "        model_file, extra_data = self.get_model('.pkl')\n",
    "        self.model = load(open(model_file, 'rb'))\n",
    "\n",
    "    def predict(self, body: dict) -> List:\n",
    "        \"\"\"Generate model predictions from sample.\"\"\"\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        result: np.ndarray = self.model.predict(feats)\n",
    "        return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-step-deploy-the-serving-function\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Deploying the Model-Serving Function (Service)\n",
    "\n",
    "To provision (deploy) a function for serving the model (\"a serving function\") you need to create an MLRun function of type `serving`.\n",
    "You can do this by using the `code_to_function` MLRun method from a web notebook, or by importing an existing serving function or template from the MLRun functions marketplace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-convert-serving-class-to-function\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a Serving Class to a Serving Function\n",
    "\n",
    "The following code converts the `ClassifierModel` class that you defined in the previous step to a serving function.\n",
    "The name of the class to be used by the serving function is set in `spec.default_class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import code_to_function\n",
    "serving_fn = code_to_function('serving', kind='serving',image='mlrun/mlrun')\n",
    "serving_fn.spec.default_class = 'ClassifierModel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the model created in previous notebook by the training function  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.serving.states.TaskState at 0x7f6f9acf7e10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = f'store://{project_name}/train-iris-train_iris_model'\n",
    "serving_fn.add_model('my_model',model_path=model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_fn = serving_fn.apply(mlrun.mount_v3io(remote='projects',mount_path='/v3io/projects'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-building-and-deploying-the-serving-function\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Deploying the Serving Function\n",
    "\n",
    "Use the `deploy` method of the MLRun serving function to build and deploy a Nuclio serving function from your serving-function code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-01-24 19:11:22,369 [info] Starting remote function deploy\n",
      "2021-01-24 19:11:22  (info) Deploying function\n",
      "2021-01-24 19:11:22  (info) Building\n",
      "2021-01-24 19:11:22  (info) Staging files and preparing base images\n",
      "2021-01-24 19:11:22  (info) Building processor image\n",
      "2021-01-24 19:11:23  (info) Build complete\n",
      "2021-01-24 19:11:29  (info) Function deploy complete\n",
      "> 2021-01-24 19:11:30,075 [info] function deployed, address=default-tenant.app.aefccdjffbit.iguazio-cd0.com:31537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://default-tenant.app.aefccdjffbit.iguazio-cd0.com:31537'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_fn.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'serving'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_fn.spec.base_spec.get('metadata').get('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-step-using-the-serving-function\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Using the Model-Serving Function\n",
    "\n",
    "After the function is deployed successfully, the serving function has a new HTTP endpoint for handling serving requests.\n",
    "The example tutorial serving function receives HTTP prediction (inference) requests on this endpoint; calls the `predict` method to get the requested predictions; and returns the results on the same endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The address for the function is default-tenant.app.aefccdjffbit.iguazio-cd0.com:31537 \n",
      "\n",
      "{\"name\": \"ModelRouter\", \"version\": \"v2\", \"extensions\": []}"
     ]
    }
   ],
   "source": [
    "function_address = serving_fn.status.address\n",
    "print (f'The address for the function is {function_address} \\n')\n",
    "\n",
    "!curl $function_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-testing-the-model-server\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model Server\n",
    "\n",
    "Test your model server by sending data for inference.\n",
    "The `invoke` serving-function method enables programmatic testing of the serving function.\n",
    "For model inference (predictions), specify the model name followed by `infer`:\n",
    "```\n",
    "/v2/models/{model_name}/infer\n",
    "```\n",
    "For complete model-service API commands &mdash; such as for list models (`models`), get model health (`ready`), and model explanation (`explain`) &mdash; see the [MLRun documentation](https://github.com/mlrun/mlrun/blob/release/v0.6.x-latest/mlrun/serving/README.md#model-server-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5c811695-d612-432d-92c1-f01204935971',\n",
       " 'model_name': 'my_model',\n",
       " 'outputs': [0, 2]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = '''{\"inputs\":[[5.1, 3.5, 1.4, 0.2],[7.7, 3.8, 6.7, 2.2]]}'''\n",
    "serving_fn.invoke('/v2/models/my_model/infer', my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-step-view-serving-func-in-ui\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Viewing the Nuclio Serving Function on the Dashboard\n",
    "\n",
    "On the **Projects** dashboad page, select the project and then select \"Real-time functions (Nuclio)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_static/images/nuclio-deploy.png\" alt=\"Jobs\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-3-step-save-project\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "Congratulation! You've completed Part 3 of the MLRun getting-started tutorial.\n",
    "Proceed to [Part 4](04-pipeline.ipynb) to learn how to create an automated pipeline for your project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

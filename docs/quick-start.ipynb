{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick-Start Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLRun** is an end-to-end open source MLOps solution to manage and automate your entire analytics and machine learning lifecycle, from data ingestion through model development and full pipeline deployment. MLRun is running as a built-in service in Iguazio and is integrated well with other services in the platform.\n",
    "Its primary goal is to ease the development of machine learning pipeline at scale and help organization to build a robust process for moving from the research phase to a full operational production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Working with MLRun](#working-with-mlrun)\n",
    "  - [Train Model](#train-model)\n",
    "  - [Test Model](#test-model)\n",
    "  - [Serve Model](#serve-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MLRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to install MLRun, refer to the [Installation Guide](install.md). Note that if are using the Iguazio platform installed, then the MLRun service is preinstalled. \n",
    "\n",
    "Open Jupyter Lab on [**jupyter-lab UI**](http://localhost:30040) and create a new notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin, initialize MLRun by calling `set_environment` and provide it the project name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import set_environment\n",
    "project_name = 'quick-start'\n",
    "_, artifact_path = set_environment(project=project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLRun introduces the concept of [functions](./runtimes/functions.md). You can run your own code as functions, or use functions from the function marketplace.\n",
    "In the example below, we'll use the [`sklearn_classifer`](https://github.com/mlrun/functions/tree/master/sklearn_classifier) from the function marketplace to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import import_function\n",
    "from mlrun.platforms import auto_mount\n",
    "\n",
    "train = import_function('hub://sklearn_classifier').apply(auto_mount())\n",
    "\n",
    "train_run = train.run(name='train',\n",
    "                      inputs={'dataset': 'https://s3.wasabisys.com/iguazio/data/iris/iris_dataset.csv'},\n",
    "                      params={'model_pkg_class': 'sklearn.linear_model.LogisticRegression',\n",
    "                              'label_column': 'label'},\n",
    "                      project=project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the [**MLRun UI**](http://localhost:30050) to see the details of this job:\n",
    "\n",
    "<img src=\"./_static/images/mlrun-quick-start-train-info.png\" alt=\"ui-info\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as artifacts:\n",
    "\n",
    "<img src=\"./_static/images/mlrun-quick-start-train-artifacts.png\" alt=\"ui-artifacts\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the function in a Jupyter notebook, the output cell for your function execution will contain a table with run information &mdash; including the state of the execution, all inputs and parameters, and the execution results and artifacts.\n",
    "\n",
    "![MLRun quick start train output](./_static/images/mlrun-quick-start-train-output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a trained model, you can test it: run a task that uses the [`test_classifier` marketplace](https://github.com/mlrun/functions/tree/master/test_classifier) function to run the selected trained model against the test data set, as returned for the training task (train) in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = import_function('hub://test_classifier').apply(auto_mount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then run the function as part of your project, just as any other function that you have written yourself. To view the function documentation, call the `doc` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function: test-classifier\n",
      "test a classifier using held-out or new data\n",
      "default handler: test_classifier\n",
      "entry points:\n",
      "  test_classifier: Test one or more classifier models against held-out dataset\n",
      "\n",
      "Using held-out test features, evaluates the peformance of the estimated model\n",
      "\n",
      "Can be part of a kubeflow pipeline as a test step that is run post EDA and \n",
      "training/validation cycles\n",
      "    context  - the function context, default=\n",
      "    models_path(DataItem)  - artifact models representing a file or a folder, default=\n",
      "    test_set(DataItem)  - test features and labels, default=\n",
      "    label_column(str)  - column name for ground truth labels, default=\n",
      "    score_method(str)  - for multiclass classification, default=micro\n",
      "    plots_dest(str)  - dir for test plots, default=\n",
      "    model_evaluator  - NOT IMPLEMENTED: specific method to generate eval, passed in as string or available in this folder, default=None\n",
      "    default_model(str)  - , default=model.pkl\n",
      "    predictions_column(str)  - column name for the predictions column on the resulted artifact, default=yscore\n",
      "    model_update  - (True) update model, when running as stand alone no need in update, default=True\n"
     ]
    }
   ],
   "source": [
    "test.doc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure parameters for the test function (`params`), and provide the selected trained model from the train task as an input artifact (`inputs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = test.run(name=\"test\",\n",
    "                    params={\"label_column\": \"label\"},\n",
    "                    inputs={\"models_path\": train_run.outputs['model'],\n",
    "                            \"test_set\": train_run.outputs['test_set']},\n",
    "                    project=project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLRun serving can take MLRun models or standard model files and produce managed real-time serverless functions based\n",
    "on Nuclio real-time serverless engine, which can be deployed everywhere. see [MLRun Serving documentation](./serving/serving-graph.md).\n",
    "\n",
    "[Nuclio](https://github.com/nuclio/nuclio) is a high-performance \"serverless\" framework focused on data, I/O, and compute intensive workloads.\n",
    "\n",
    "To deploy your model using the [`v2_model_server` function](https://github.com/mlrun/functions/tree/master/v2_model_server) run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-01-20 18:53:09,878 [info] Starting remote function deploy\n",
      "2021-01-20 18:53:09  (info) Deploying function\n",
      "2021-01-20 18:53:09  (info) Building\n",
      "2021-01-20 18:53:10  (info) Staging files and preparing base images\n",
      "2021-01-20 18:53:10  (info) Building processor image\n",
      "2021-01-20 18:56:17  (info) Build complete\n",
      "2021-01-20 18:56:23  (info) Function deploy complete\n",
      "> 2021-01-20 18:56:24,185 [info] function deployed, address=192.168.26.1:31079\n"
     ]
    }
   ],
   "source": [
    "serve = import_function('hub://v2_model_server').apply(auto_mount())\n",
    "model_name='iris'\n",
    "serve.add_model(model_name, model_path=train_run.outputs['model'])\n",
    "addr = serve.deploy(project=project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `invoke` method enables to programmatically test the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '50ab7901-526e-4cdd-a56a-e37fd0872907',\n",
       " 'model_name': 'iris',\n",
       " 'outputs': [0, 2]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "inputs = [[5.1, 3.5, 1.4, 0.2],\n",
    "          [7.7, 3.8, 6.7, 2.2]]\n",
    "my_data = json.dumps({'inputs': inputs})\n",
    "serve.invoke(f'v2/models/{model_name}/infer', my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the [**Nuclio UI**](http://localhost:30040) to view the function and test it.\n",
    "\n",
    "![MLRun serving UI](./_static/images/mlrun-quick-start-serve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more detailed, refer to the [End-to-end Pipeline Tutorial](end-to-end-pipeline.rst)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
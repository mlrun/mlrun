(build-function-image)=
# Build function image

As discussed in {ref}`images-usage`, MLRun provides pre-built images which contain the components necessary to execute
an MLRun runtime. In some cases, however, these images are not enough and custom images need to be created. 
This page details this process and the available options.

## When is a build required?

As mentioned, in many cases an MLRun runtime can be executed without having to build an image. This will be true when
the basic MLRun images provide all the requirements for the code to execute. In a nutshell, an image build will be
needed if one of the following is true:

1. Using additional Python packages, OS packages, scripts or other configurations that need to be applied
2. Using different base-images or different versions of MLRun images than used by default
3. Executed source code has changed, and the image has the code packaged in it - see
   [here](mlrun_jobs.html#deploy-build-the-function-container) for more details on source code, and using 
   {py:func}`~mlrun.runtimes.BaseRuntime.with_code()` to avoid re-building the image when the code has changed
4. Running nuclio functions, which are packaged as images (build is triggered by MLRun and performed by nuclio)

The build process in MLRun is based on [Kaniko](https://github.com/GoogleContainerTools/kaniko) and automated by MLRun -
the dockerfile needed for the deployment process is generated by MLRun, as well as supplying Kaniko with secrets needed
for container repository access - these are provided as part of the MLRun installation, and can be overridden
manually by using the {py:func}`~mlrun.runtimes.KubejobRuntime.build_config()` function.

Building the image is triggered by calling the `deploy()` function of the runtime. 
MLRun has the capability to auto-detect when a function needs to first be deployed. This can be done by using the 
`auto_build` parameter when running the function:

```{code-block} python
:emphasize-lines: 9-9

trainer = mlrun.code_to_function(
    name='my-trainer',
    kind='job', 
    image='mlrun/mlrun', 
    requirements=['pandas']
)

# Build will be triggered, since the function has extra requirements.
trainer.run(auto_build=True)
```

See also the documentation of the {py:func}`~mlrun.runtimes.BaseRuntime.run()` function.

## Modifying build configuration

When building the image, MLRun runtimes provide several facilities to add or modify the build configuration. 
The {py:func}`~mlrun.runtimes.KubejobRuntime.build_config()` function provides a single interface through which most
of the build configurations can be set.

### Specifying base image
To use an existing image as the base image for building the image, either use the 
{py:func}`~mlrun.runtimes.KubejobRuntime.build_config()` function or the following:

```python
function.spec.build.base_image = 'repo/image:tag'
```

Note that this is the image that will be serving as base (dockerfile `FROM` property), not to be confused with the 
resulting image name, as specified in the `image` parameter of `code_to_function` and similar functions.

### Adding Python package requirements
To include additional Python packages (installed using `pip`), using the following methods:

```{code-block} python
:emphasize-lines: 6-6

# Specify additional requirements when calling code_to_function
trainer = mlrun.code_to_function(
    name='my-trainer',
    kind='job', 
    image='mlrun/mlrun', 
    requirements=['pandas']
)

# Alternatively, call the function's with_requirements method
trainer.with_requirements(['pandas'])
```

Each of the requirements specified will result in a build command that will run `pip install` of the package 
specified.

### Running commands
To run arbitrary commands during the image build, pass them to 
the {py:func}`~mlrun.runtimes.KubejobRuntime.build_config()` function or modify the runtime's `spec.build.commands` 
list. For example:

```python
github_repo = "myusername/myrepo.git@mybranch"
function.spec.build.commands = [
    "pip install git+https://github.com/" + github_repo,
    "mkdir -p /some/path && chmod 0777 /some/path",
]
```

These commands will be added as `RUN` operations to the dockerfile generating the image.

## Spark runtime images
When using Spark to execute code, either using a Spark service (remote-spark) or the Spark operator, an image is 
required which contains both Spark binaries and dependencies and MLRun code and dependencies. 
This image is used in the following scenarios:

1. For remote-spark, the image is used to run the initial MLRun code which will submit the Spark job using the 
   remote Spark service
2. For Spark operator, the image is used for both the driver and the executor pods used to execute the Spark job

This image needs to be created any time a new version of Spark or MLRun is being used, to ensure that jobs are executed
with the correct versions of both products.

To prepare this image, MLRun provides the following facilities:

```python
# For remote Spark
from mlrun.runtimes import RemoteSparkRuntime
RemoteSparkRuntime.deploy_default_image()

# For Spark operator
from mlrun.runtimes import Spark3Runtime
Spark3Runtime.deploy_default_image()
```

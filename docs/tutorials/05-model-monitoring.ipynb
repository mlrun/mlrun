{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8f6c9f",
   "metadata": {},
   "source": [
    "(realtime-monitor-drift-tutor)=\n",
    "# Realtime monitoring and drift detection\n",
    "\n",
    "This tutorial illustrates the basic model monitoring capabilities of MLRun: deploying a model to a live endpoint and \n",
    "calculating data drift.\n",
    "\n",
    "See the overview to model monitoring in {ref}`model-monitoring-des`, and \n",
    "make sure you have reviewed the basics in MLRun [**Quick Start Tutorial**](../01-mlrun-basics.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c9e94",
   "metadata": {},
   "source": [
    "## MLRun installation and configuration\n",
    "\n",
    "Before running this notebook make sure `mlrun` is installed and that you have configured the access to the MLRun service. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd4c68",
   "metadata": {},
   "source": [
    "## Set up the project\n",
    "\n",
    "First, import the dependencies and create an [MLRun project](https://docs.mlrun.org/en/latest/projects/project.html). This  contains all of the models, functions, datasets, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c548d350-83c5-4886-8f96-401c8c139b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-09-10 11:51:45,392 [info] Server and client versions are not the same but compatible: {'parsed_server_version': Version(major=1, minor=7, patch=0, prerelease='rc40', build=None), 'parsed_client_version': Version(major=1, minor=6, patch=3, prerelease=None, build=None)}\n",
      "> 2024-09-10 11:51:45,430 [info] Loading project from path: {'project_name': 'tutorial', 'path': './'}\n",
      "> 2024-09-10 11:52:00,855 [info] Project loaded successfully: {'project_name': 'tutorial', 'path': './', 'stored_in_db': True}\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import mlrun\n",
    "from mlrun import import_function, get_dataitem, get_or_create_project\n",
    "import uuid\n",
    "\n",
    "project_name = \"tutorial\"\n",
    "project = get_or_create_project(project_name, context=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8944e0-565a-4bc2-9515-e9a8f9724fb8",
   "metadata": {},
   "source": [
    "```{admonition} Note\n",
    "This tutorial does not focus on training a model. Instead, it starts with a trained model and its corresponding training dataset.\n",
    "```\n",
    "\n",
    "## Enable model monitoring\n",
    "\n",
    "Model monitoring is enabled per project. {py:meth}`~mlrun.projects.MlrunProject.enable_model_monitoring` brings up the controller and schedules it according to the `base_period`, and deploys the writer.\n",
    "\n",
    "The controller runs, by default, every 10 minutes, which is also the minimum interval. You can modify the frequency with the parameter `base_period`. To change the `base_period`, first run {py:meth}`~mlrun.projects.MlrunProject.disable_model_monitoring`, then run `enable_model_monitoring` with the new `base_period` value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1bcc3d-77d4-45ad-9048-7586c65ab346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Submitted the model-monitoring controller, writer and stream deployment'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_model_monitoring_credentials(None, \"v3io\", \"v3io\")\n",
    "project.enable_model_monitoring(base_period=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1de530",
   "metadata": {},
   "source": [
    "## Log the model artifacts\n",
    "\n",
    "See full parameter details in {py:meth}`~mlrun.projects.MlrunProject.log_model`.\n",
    "\n",
    "First download {download}`the pickle file <./src/model.pkl>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee81d857-7c02-4687-bb3d-92f0f3e05c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.artifacts.model.ModelArtifact at 0x7fc1921f7850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "train_set = pd.DataFrame(\n",
    "    iris[\"data\"],\n",
    "    columns=[\"sepal_length_cm\", \"sepal_width_cm\", \"petal_length_cm\", \"petal_width_cm\"],\n",
    ")\n",
    "\n",
    "model_name = \"RandomForestClassifier\"\n",
    "project.log_model(\n",
    "    model_name,\n",
    "    model_file=\"model.pkl\",\n",
    "    training_set=train_set,\n",
    "    framework=\"sklearn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1993e5-94c8-472d-b026-e1f6e5f89297",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import, enable monitoring, and deploy the serving function\n",
    "\n",
    "Import the [model server function](https://www.mlrun.org/hub/functions/master/v2-model-server/latest/example/)  from the MLRun Function Hub, add the model that was logged via experiment tracking, and enable drift detection.\n",
    "\n",
    "The model monitoring infrastructure was already enabled in [Enable model monitoring](#enable-model-monitoring). Now, you enable monitoring on this specific function and its related models with `set_tracking`. This activates all inferences and predictions, which is used for drift detection.\n",
    "\n",
    "Then you deploy the serving function with drift detection enabled with a single line of code.\n",
    "\n",
    "The result of this step is that the model-monitoring stream pod writes data to Parquet, by model endpoint. Every base period, the controller checks for new data. Each time it finds new data, it sends it to the relevant app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ea9061-00d8-4914-b4a5-90c0beb23180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-09-10 12:01:43,675 [info] Starting remote function deploy\n",
      "2024-09-10 12:01:44  (info) Deploying function\n",
      "2024-09-10 12:01:44  (info) Building\n",
      "2024-09-10 12:01:44  (info) Staging files and preparing base images\n",
      "2024-09-10 12:01:44  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2024-09-10 12:01:44  (info) Building processor image\n",
      "2024-09-10 12:05:09  (info) Build complete\n",
      "2024-09-10 12:05:53  (info) Function deploy complete\n",
      "> 2024-09-10 12:05:57,200 [info] Successfully deployed function: {'internal_invocation_urls': ['nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['tutorial-serving.default-tenant.app.vmdev94.lab.iguazeng.com/']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeployStatus(state=ready, outputs={'endpoint': 'http://tutorial-serving.default-tenant.app.vmdev94.lab.iguazeng.com/', 'name': 'tutorial-serving'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the serving function\n",
    "serving_fn = import_function(\n",
    "    \"hub://v2_model_server\", project=project_name, new_name=\"serving\"\n",
    ")\n",
    "\n",
    "# Add the model to the serving function's routing spec\n",
    "serving_fn.add_model(\n",
    "    model_name, model_path=f\"store://models/{project_name}/{model_name}:latest\"\n",
    ")\n",
    "\n",
    "# Enable monitoring on this serving function\n",
    "serving_fn.set_tracking()\n",
    "\n",
    "serving_fn.spec.build.requirements = [\"scikit-learn\"]\n",
    "\n",
    "# Deploy the serving function\n",
    "project.deploy_function(serving_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1386e06-5bd0-4206-84a1-73d88dcf1bbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## View deployed resources\n",
    "\n",
    "At this point, you should see the model-monitoring-controller job in the UI under **Projects | Jobs and Workflows**.\n",
    "\n",
    "## Invoke the model\n",
    "\n",
    "See full parameter details in {py:meth}`~mlrun.runtimes.RemoteRuntime.invoke`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d56d6d94-f40a-43d8-b9bf-9a6a8ca401b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-09-11 09:00:18,459 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:00:18,901 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:00:18,962 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:00:19,030 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:00:19,094 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:00:19,123 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:00:19,152 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:00:19,217 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from time import sleep\n",
    "from random import choice, uniform\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris[\"data\"].tolist()\n",
    "\n",
    "model_name = \"RandomForestClassifier\"\n",
    "serving_1 = project.get_function(\"serving\")\n",
    "0\n",
    "for i in range(150):\n",
    "    data_point = choice(iris_data)\n",
    "    serving_1.invoke(\n",
    "        f\"v2/models/{model_name}/infer\", json.dumps({\"inputs\": [data_point]})\n",
    "    )\n",
    "    sleep(choice([0.01, 0.04]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367392df-0760-41ef-8881-b7e3b4bd90c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "At this stage you can see the model endpoints and minimal meta data (for example, last prediction and average latency) in the **Models | Model Endpoints** page. \n",
    "\n",
    "<img src=\"./_static/images/model_endpoint_1.png\" width=\"1000\" >\n",
    "\n",
    "You can also see the basic statistics in Grafana.\n",
    "\n",
    "## Register and deploy the model-monitoring apps\n",
    "\n",
    "The next step is to deploy the model-monitoring app to generate the full meta data. Add the monitoring app to the project using {py:meth}`~mlrun.projects.MlrunProject.set_model_monitoring_function`. \n",
    "Then, deploy the app using {py:meth}`~mlrun.projects.MlrunProject.deploy_function`.\n",
    "\n",
    "This example illustrates two monitoring apps:\n",
    "- The first is the default monitoring app.\n",
    "- The second integrates [Evidently](https://github.com/evidentlyai/evidently) as an MLRun function to create MLRun artifacts.\n",
    "\n",
    "After deploying the jobs they show in the UI under Real-time functions (Nuclio).\n",
    "\n",
    "### Default monitoring app\n",
    "\n",
    "First download the {download}`demo_app <./src/demo_app.py>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c078d0e-34e3-4c50-8e4e-895414fa000e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-09-10 12:07:14,544 [info] Starting remote function deploy\n",
      "2024-09-10 12:07:14  (info) Deploying function\n",
      "2024-09-10 12:07:15  (info) Building\n",
      "2024-09-10 12:07:15  (info) Staging files and preparing base images\n",
      "2024-09-10 12:07:15  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2024-09-10 12:07:15  (info) Building processor image\n",
      "2024-09-10 12:09:00  (info) Build complete\n",
      "2024-09-10 12:09:20  (info) Function deploy complete\n",
      "> 2024-09-10 12:09:27,034 [info] Successfully deployed function: {'internal_invocation_urls': ['nuclio-tutorial-myapp.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeployStatus(state=ready, outputs={'endpoint': 'http://', 'name': 'tutorial-myapp'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register the first app named \"demo_app\"\n",
    "my_app = project.set_model_monitoring_function(\n",
    "    func=\"demo_app.py\",\n",
    "    application_class=\"DemoMonitoringApp\",\n",
    "    name=\"myApp\",\n",
    ")\n",
    "\n",
    "project.deploy_function(my_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878a4ff9",
   "metadata": {},
   "source": [
    "### Evidently app\n",
    "\n",
    "First download {download}`evidently_app <./src/evidently_app>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bea6e8fb-c6d5-44f6-a46e-7c8a01e295ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-09-10 12:10:16,691 [info] Starting remote function deploy\n",
      "2024-09-10 12:10:17  (info) Deploying function\n",
      "2024-09-10 12:10:17  (info) Building\n",
      "2024-09-10 12:10:17  (info) Staging files and preparing base images\n",
      "2024-09-10 12:10:17  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2024-09-10 12:10:17  (info) Building processor image\n",
      "2024-09-10 12:12:58  (info) Build complete\n",
      "2024-09-10 12:13:22  (info) Function deploy complete\n",
      "> 2024-09-10 12:13:29,643 [info] Successfully deployed function: {'internal_invocation_urls': ['nuclio-tutorial-myevidentlyapp.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeployStatus(state=ready, outputs={'endpoint': 'http://', 'name': 'tutorial-myevidentlyapp'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register the second app named \"evidently_app\"\n",
    "my_evidently_app = project.set_model_monitoring_function(\n",
    "    func=\"evidently_app.py\",\n",
    "    image=\"mlrun/mlrun\",\n",
    "    requirements=[\n",
    "        \"evidently~=0.4.3\",\n",
    "    ],\n",
    "    name=\"MyEvidentlyApp\",\n",
    "    application_class=\"DemoEvidentlyMonitoringApp\",\n",
    "    evidently_workspace_path=os.path.abspath(\n",
    "        f\"/v3io/projects/{project_name}/artifacts/evidently_workspace\"\n",
    "    ),\n",
    "    evidently_project_id=str(uuid.uuid4()),\n",
    ")\n",
    "\n",
    "project.deploy_function(my_evidently_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6f414b-dccd-45b1-9dc8-ada2c82b85cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Invoke the model again\n",
    "The controller checks for new datasets every `base_period` to send to the app. Invoking the model a second time ensures that the previous window closed and therefore the data contains the full monitoring window. From this point on, the applications are triggered by the controller. The controller checks the Parquet DB every 10 minutes (or non-default \n",
    "`base_period`) and streams any new data to the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "906174a1-d300-4860-ae41-1284fe9b544a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-09-11 09:32:28,831 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:32:29,171 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:32:29,198 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:32:29,222 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:32:29,250 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n",
      "> 2024-09-11 09:32:29,275 [info] Invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-serving.default-tenant.svc.cluster.local:8080/v2/models/RandomForestClassifier/infer'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from time import sleep\n",
    "from random import choice, uniform\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris[\"data\"].tolist()\n",
    "\n",
    "model_name = \"RandomForestClassifier\"\n",
    "serving_1 = project.get_function(\"serving\")\n",
    "\n",
    "for i in range(150):\n",
    "    data_point = choice(iris_data)\n",
    "    serving_1.invoke(\n",
    "        f\"v2/models/{model_name}/infer\", json.dumps({\"inputs\": [data_point]})\n",
    "    )\n",
    "    sleep(choice([0.01, 0.04]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf342a-aa6f-4898-87c1-a4976bd283a8",
   "metadata": {},
   "source": [
    "## View the application results\n",
    "\n",
    "<img src=\"./_static/images/mm-myapp.png\" >\n",
    "\n",
    "And if you've used Evidently:\n",
    "\n",
    "<img src=\"./_static/images/mm-logger-dashb-evidently.png\" >\n",
    "\n",
    "And an example from the various graphs:\n",
    "\n",
    "<img src=\"./_static/images/mm-evidently.png\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09c03d",
   "metadata": {},
   "source": [
    "## View the status of the model monitoring jobs \n",
    "\n",
    "View the model monitoring jobs in Jobs and Workflows. Model monitoring jobs run continuously, therefore they should \n",
    "have a blue dot indicating that the function is running. (A green dot indicates that the job completed.)\n",
    "\n",
    "For more information on the UI, see [Model monitoring using the platform UI](../monitoring/model-monitoring-deployment.html#model-monitoring-in-the-platform-ui).\n",
    "\n",
    "<img src=\"./_static/images/mm-monitor-jobs.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa41b3",
   "metadata": {},
   "source": [
    "<a id=\"view-dashboards\"></a>\n",
    "## View detailed drift dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e0309",
   "metadata": {},
   "source": [
    "Grafana has detailed dashboards that show additional information on each model in the project:\n",
    "\n",
    "For more information on the dashboards, see [Model monitoring in the Grafana dashboards](../model-monitoring/monitoring-models.html#model-monitoring-in-the-grafana-dashboards).\n",
    "\n",
    "The **Overview** dashboard displays the model endpoint IDs of a specific project. Only deployed models with Model Monitoring enabled are displayed. Endpoint IDs are URIs used to provide access to performance data and drift detection statistics of a deployed model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4d7c9c",
   "metadata": {},
   "source": [
    "![grafana_dashboard_1](./_static/images/grafana_dashboard_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef9345",
   "metadata": {},
   "source": [
    "The **Model Monitoring Details** dashboard displays the real-time performance data of the selected model, including graphs of individual features over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da470eca",
   "metadata": {},
   "source": [
    "![grafana_dashboard_2](./_static/images/grafana_dashboard_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ce647b",
   "metadata": {},
   "source": [
   "The **Model Monitoring Performance** dashboard displaysdrift and operational metrics over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54888c18",
   "metadata": {},
   "source": [
    "![grafana_dashboard_3](./_static/images/grafana_dashboard_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ed1fc",
   "metadata": {},
   "source": [
    "## Done!\n",
    "Congratulations! You’ve completed Part 5 of the MLRun getting-started tutorial. To continue, proceed to [Part 6 Batch inference and drift detection](./07-batch-infer)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MLRun Projects and GIT\n",
    "  --------------------------------------------------------------------\n",
    "\n",
    "Loading or creating a full project with multiple functions and workflow and working wit Git.\n",
    "\n",
    "#### **notebook how-to's**\n",
    "* Load a project with multiple functions from Git\n",
    "* Run automated workflows (using KubeFlow)\n",
    "* Update, maintain and debug code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "#### **steps**\n",
    "**[Load project from Git or Archive](#load-project)**<br>\n",
    "**[Run a pipeline workflow](#run-pipeline)**<br>\n",
    "**[Updating the project and code](#update-project)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import load_project, mlconf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-project'></a>\n",
    "## Load project from Git or Archive\n",
    "\n",
    "Projects can be stored in a Git repo or in a tar archive (on object store like S3, V3IO).\n",
    "\n",
    "`load_project(context, url)` will load/clone the project to the local context dir and build the project object from the `project.yaml` file in the git/archive root directory. \n",
    "\n",
    "> Note: If URL is not specified it will use the context and search for Git repo inside it, or use the `init_git=True` flag to initialize a Git repo in the target context directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source Git Rep, it is recommended to fork this to your account\n",
    "url = 'git://github.com/mlrun/demo-xgb-project.git'\n",
    "\n",
    "# alternatively can use tar files\n",
    "#url = 'v3io:///users/admin/tars/src-project.tar.gz'\n",
    "\n",
    "proj = load_project('/User/my-proj', url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the project object, note it contains lists of `functions` and `workflows` which will be used in the project. Functions can be local to the project or referenced to (via a URL to .ipynb, .py, .yaml file and/or container image). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: iris\n",
      "functions:\n",
      "- url: function.yaml\n",
      "  name: xgb\n",
      "- url: https://raw.githubusercontent.com/mlrun/functions/master/serving/xgboost/xgb_serving.ipynb\n",
      "  name: serving\n",
      "workflows:\n",
      "  main: workflow.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(proj.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'git://github.com/mlrun/demo-xgb-project.git'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: job\n",
      "metadata:\n",
      "  name: iris-demo\n",
      "  project: iris\n",
      "spec:\n",
      "  command: iris.py\n",
      "  args: []\n",
      "  image: ''\n",
      "  volumes: []\n",
      "  volume_mounts: []\n",
      "  env: []\n",
      "  description: ''\n",
      "  build:\n",
      "    source: git://github.com/mlrun/demo-xgb-project.git\n",
      "    base_image: mlrun/mlrun\n",
      "    commands:\n",
      "    - pip install sklearn\n",
      "    - pip install xgboost\n",
      "    - pip install matplotlib\n",
      "    code_origin: https://github.com/mlrun/demo-xgb-project.git#262443b810b158daca1a6058c45299b410edf7fa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read specific function spec\n",
    "print(proj.func('xgb').to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-pipeline'></a>\n",
    "## Run a pipeline workflow\n",
    "You can check the `workflow.py` file to see how functions objects are initialized and used (by name) inside the workflow.\n",
    "The `workflow.py` file has two parts, initialize the function objects and define pipeline dsl (connect the function inputs and outputs).\n",
    "\n",
    "> Note the pipeline can include CI steps like building container images and deploying models.\n",
    "\n",
    "### Initializing the functions (e.g. mount them on the v3io fabric)\n",
    "```python\n",
    "def init_functions(functions: dict, params=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        \n",
    "```\n",
    "<br>\n",
    "\n",
    "### Workflow DSL:\n",
    "```python\n",
    "@dsl.pipeline(\n",
    "    name='My XGBoost training pipeline',\n",
    "    description='Shows how to use mlrun.'\n",
    ")\n",
    "def kfpipeline(\n",
    "        eta=[0.1, 0.2, 0.3], gamma=[0.1, 0.2, 0.3]\n",
    "):\n",
    "    # first step build the function container\n",
    "    builder = funcs['xgb'].deploy_step(with_mlrun=False)\n",
    "\n",
    "    # use xgb.iris_generator function to generate data (container image from the builder)\n",
    "    ingest = funcs['xgb'].as_step(name='ingest_iris', handler='iris_generator',\n",
    "        image=builder.outputs['image'],\n",
    "        params={'target': df_path},\n",
    "        outputs=['iris_dataset'], out_path=artifacts_path)\n",
    "\n",
    "    # use xgb.xgb_train function to train on the data (from the generator step)\n",
    "    train = funcs['xgb'].as_step(name='xgb_train', handler='xgb_train',\n",
    "        image=builder.outputs['image'],\n",
    "        hyperparams={'eta': eta, 'gamma': gamma},\n",
    "        selector='max.accuracy',\n",
    "        inputs={'dataset': ingest.outputs['iris_dataset']},\n",
    "        outputs=['model'], out_path=artifacts_path)\n",
    "\n",
    "    # deploy the trained model using a nuclio real-time function\n",
    "    deploy = funcs['serving'].deploy_step(models={'iris_v1': train.outputs['model']})\n",
    "```\n",
    "\n",
    "### Run\n",
    "use the `run` method to execute a workflow, you can provide alternative arguments and specify the default target for workflow artifacts.<br>\n",
    "The workflow ID is returned and can be used to track the progress or you can use the hyperlinks\n",
    "\n",
    "> Note: The same command can be issued through CLI commands:<br>\n",
    "    `mlrun project my-proj/ -r main -p \"v3io:///users/admin/mlrun/kfp/{{workflow.uid}}/\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/User/.pythonlibs/jupyter/lib/python3.6/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"[0.1, 0.2, 0.3]\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd2.com/pipelines/#/experiments/details/4f76db7f-7514-47e5-aab2-afee0558afce\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd2.com/pipelines/#/runs/details/0c9d0ecc-3b58-45eb-9f63-6da00420567a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-02-22 23:49:56,310 Pipeline run id=0c9d0ecc-3b58-45eb-9f63-6da00420567a, check UI or DB for progress\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0c9d0ecc-3b58-45eb-9f63-6da00420567a'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.run('main', arguments={}, artifacts_path='v3io:///users/admin/mlrun/kfp/{{workflow.uid}}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='update-project'></a>\n",
    "## Updating the project and code\n",
    "\n",
    "A user can update the code using the standard Git process (commit, push, ..), if you update/edit the project object you need to run `proj.save()` which will update the `project.yaml` file in your context directory, followed by pushing your updates.\n",
    "\n",
    "You can use `proj.push(branch, commit_message)` which will do the work for you (save the yaml, commit updates, push)\n",
    "\n",
    "> Note: you must push updates before you build functions or run workflows since the builder will pull the code from the git repo.\n",
    "\n",
    "If you are using containerized Jupyter you may need to first set your Git parameters, e.g.:\n",
    "\n",
    "```\n",
    "!git config --global user.email \"<my@email.com>\"\n",
    "!git config --global user.name \"<name>\"\n",
    "!git config --global credential.helper store\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.push('master', 'some edits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to pull changes done by others use `proj.pull()`, if you need to update the project spec (since the yaml file changed) use `proj.reload()` and for updating the local/remote function specs use `proj.sync_functions()` (or add `sync=True` to `.reload()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing the source path to speed debug\n",
    "\n",
    "Instead of updating Git anytime we modify code we can build the code from the shared file system on the cluster (the build container will mount to the same location with the code instead of reading from Git).\n",
    "\n",
    "We need to change the project source to point to the shared file system URL of our context directory (e.g. v3io), and we can re-run the workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.source = 'v3io:///users/admin/my-proj'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[back to top](#top)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

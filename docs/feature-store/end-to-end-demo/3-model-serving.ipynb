{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part 3: Serving\n",
    "In this part we will user MLRun's **serving runtime** to deploy our trained models from the previous stage a `Voting Ensemble` using **max vote** logic.  \n",
    "We will also use MLRun's **Feature store** to receive the latest tag of the online **Feature Vector** we defined in the preveious stage.\n",
    "\n",
    "By the end of this tutorial youâ€™ll learn how to:\n",
    "- Define a model class to load our models, run preprocessing and predict on the data\n",
    "- Define Voting Ensemble function on top of our models\n",
    "- Test the serving function locally using our `mock server`\n",
    "- Deploy the function to the cluster and test it live"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import mlrun"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment Setup\n",
    "\n",
    "Since our work is done in a this project scope, we will first want to define the project itself for all our MLRun work in this notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "project_name, _ = mlrun.set_environment(project='fraud-demo', \n",
    "                                        user_project=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Model Class\n",
    "- Load models\n",
    "- Predict from the FS Online service via the `source` key"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# mlrun: start-code"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cloudpickle import load\n",
    "import json\n",
    "\n",
    "import mlrun\n",
    "from mlrun.feature_store import OnlineVectorService, get_online_feature_service\n",
    "from mlrun.serving.routers import VotingEnsemble\n",
    "from mlrun.serving.v2_serving import V2ModelServer\n",
    "\n",
    "\n",
    "class ClassifierModel(V2ModelServer):\n",
    "    \n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "        model_file, extra_data = self.get_model('.pkl')\n",
    "        self.model = load(open(model_file, 'rb'))\n",
    "        \n",
    "    def predict(self, body: dict) -> list:\n",
    "        \"\"\"Generate model predictions from sample\"\"\"\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        result: np.ndarray = self.model.predict(feats)\n",
    "        return result.tolist()\n",
    "    \n",
    "    \n",
    "class EnrichmentVotingEnsemble(VotingEnsemble):\n",
    "    def __init__(\n",
    "        self,\n",
    "        context,\n",
    "        name,\n",
    "        routes=None,\n",
    "        protocol=None,\n",
    "        url_prefix=None,\n",
    "        health_prefix=None,\n",
    "        vote_type=None,\n",
    "        executor_type=None,\n",
    "        prediction_col_name=None,\n",
    "        feature_vector_uri: str = \"\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            context,\n",
    "            name,\n",
    "            routes,\n",
    "            protocol,\n",
    "            url_prefix,\n",
    "            health_prefix,\n",
    "            vote_type,\n",
    "            executor_type,\n",
    "            prediction_col_name,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.feature_vector_uri = feature_vector_uri\n",
    "        self.feature_service: Optional[OnlineVectorService] = None\n",
    "        self.feature_stats: Optional[pd.DataFrame] = None\n",
    "        self.default_category = 0\n",
    "\n",
    "    def post_init(self, mode=\"sync\"):\n",
    "        super().post_init(mode)\n",
    "        \n",
    "        self.feature_service: OnlineVectorService = get_online_feature_service(\n",
    "            feature_vector=self.feature_vector_uri\n",
    "        )\n",
    "        self.feature_stats = self.feature_service.vector.get_stats_table()\n",
    "\n",
    "    def preprocess(self, event):\n",
    "        \n",
    "        if isinstance(event.body,str) or isinstance(event.body,bytes):\n",
    "            event.body = json.loads(event.body)\n",
    "\n",
    "        \"\"\"Turn an entity identifier (source) to a Feature Vector\"\"\"\n",
    "        # Get patient feature vector\"\n",
    "        # from the patient_id given in the request\n",
    "        print(\"event body:\", event.body)\n",
    "        inputs = event.body['inputs']\n",
    "        \n",
    "        sources = [{\"source\": source} for source in inputs]\n",
    "        print(\"sources:\", sources)\n",
    "            \n",
    "        print(type(sources))\n",
    "        print(sources)\n",
    "        # here it is not serializing, error:\n",
    "        vectors = self.feature_service.get(sources)\n",
    "        print(\"vectors:\", vectors)\n",
    "        \n",
    "        # Impute inf's in the data to the feature's mean value\n",
    "        # using the collected statistics from the Feature store\n",
    "        feature_vectors = []\n",
    "        for fv in vectors:\n",
    "            if fv is None:\n",
    "                continue\n",
    "            new_vector = []\n",
    "            for f, v in fv.items():\n",
    "                if type(v) == float:\n",
    "                    if np.isinf(v) or np.isnan(v):\n",
    "                        new_vector.append(self.feature_stats.loc[f, \"mean\"])\n",
    "                    else:\n",
    "                        new_vector.append(v)\n",
    "                    continue\n",
    "                v = v if v is not None else self.default_category\n",
    "                new_vector.append(v)\n",
    "            feature_vectors.append(new_vector)\n",
    "\n",
    "        # Set the final feature vector as our inputs\n",
    "        # to pass to the predict function\n",
    "        event.body[\"inputs\"] = feature_vectors\n",
    "        \n",
    "        return event"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# mlrun: end-code"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Serving Function\n",
    "- Gather ClassifierModel code from this notebook\n",
    "- Define `VotingEnsemble` - Max-Vote based ensemble\n",
    "- Add downloaded models to the ensemble"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "feature_service: OnlineVectorService = get_online_feature_service(\n",
    "    feature_vector=\"transactions-fraud-short\"\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "feature_service.get([{\"source\": \"C1000148617\"}])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'amount_max_2h': -inf,\n",
       "  'amount_max_12h': 52.93,\n",
       "  'amount_sum_2h': 0.0,\n",
       "  'amount_count_2h': 0.0,\n",
       "  'amount_avg_2h': nan}]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from mlrun import mount_v3io\n",
    "\n",
    "# Create the serving function from our code above\n",
    "fn = mlrun.code_to_function('transaction-fraud', kind='serving', image=\"mlrun/mlrun:0.6.6\")\n",
    "\n",
    "fn.set_topology('router', 'EnrichmentVotingEnsemble', name='VotingEnsemble',\n",
    "                feature_vector_uri=\"transactions-fraud-short\")\n",
    "\n",
    "# Apply a mount so we can load the model files directly from the v3io fs\n",
    "fn.apply(mount_v3io())\n",
    "\n",
    "model_names = [\n",
    "'RandomForestClassifier',\n",
    "'GradientBoostingClassifier',\n",
    "'AdaBoostClassifier'\n",
    "]\n",
    "\n",
    "models_dir = os.path.abspath('models')\n",
    "\n",
    "for i, name in enumerate(model_names, start=1):\n",
    "    fn.add_model(name, class_name=\"ClassifierModel\", model_path=f\"store://models/{project_name}/training_model#{i}:latest\")\n",
    "\n",
    "# Plot the ensemble configuration\n",
    "fn.spec.graph.plot()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7ff3b8da0390>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: mlrun&#45;flow Pages: 1 -->\n<svg width=\"763pt\" height=\"196pt\"\n viewBox=\"0.00 0.00 763.28 196.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 192)\">\n<title>mlrun&#45;flow</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-192 759.2803,-192 759.2803,4 -4,4\"/>\n<!-- _start -->\n<g id=\"node1\" class=\"node\">\n<title>_start</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"404.0871,-152.0493 406.2376,-152.1479 408.3659,-152.2953 410.4632,-152.4913 412.5211,-152.7353 414.5313,-153.0266 416.4859,-153.3645 418.3773,-153.7479 420.1982,-154.1759 421.942,-154.6472 423.6024,-155.1606 425.1736,-155.7147 426.6502,-156.308 428.0278,-156.9388 429.3021,-157.6054 430.4697,-158.3059 431.5277,-159.0385 432.4739,-159.8012 433.3065,-160.5918 434.0245,-161.4082 434.6274,-162.2481 435.1154,-163.1093 435.4891,-163.9894 435.7498,-164.886 435.8991,-165.7965 435.9393,-166.7186 435.873,-167.6497 435.7032,-168.5873 435.4333,-169.5287 435.0671,-170.4713 434.6086,-171.4127 434.0621,-172.3503 433.4319,-173.2814 432.7227,-174.2035 431.9391,-175.114 431.086,-176.0106 430.168,-176.8907 429.19,-177.7519 428.1566,-178.5918 427.0724,-179.4082 425.942,-180.1988 424.7695,-180.9615 423.5592,-181.6941 422.3151,-182.3946 421.0407,-183.0612 419.7397,-183.692 418.4153,-184.2853 417.0705,-184.8394 415.708,-185.3528 414.3304,-185.8241 412.9398,-186.2521 411.5385,-186.6355 410.1281,-186.9734 408.7104,-187.2647 407.2868,-187.5087 405.8585,-187.7047 404.4268,-187.8521 402.9926,-187.9507 401.5571,-188 400.1211,-188 398.6856,-187.9507 397.2514,-187.8521 395.8197,-187.7047 394.3914,-187.5087 392.9678,-187.2647 391.5501,-186.9734 390.1397,-186.6355 388.7384,-186.2521 387.3478,-185.8241 385.9702,-185.3528 384.6077,-184.8394 383.2629,-184.2853 381.9385,-183.692 380.6375,-183.0612 379.3631,-182.3946 378.119,-181.6941 376.9087,-180.9615 375.7362,-180.1988 374.6058,-179.4082 373.5216,-178.5918 372.4882,-177.7519 371.5102,-176.8907 370.5922,-176.0106 369.7391,-175.114 368.9555,-174.2035 368.2463,-173.2814 367.6161,-172.3503 367.0696,-171.4127 366.6111,-170.4713 366.2449,-169.5287 365.975,-168.5873 365.8052,-167.6497 365.7389,-166.7186 365.7791,-165.7965 365.9284,-164.886 366.1891,-163.9894 366.5628,-163.1093 367.0508,-162.2481 367.6537,-161.4082 368.3717,-160.5918 369.2043,-159.8012 370.1505,-159.0385 371.2085,-158.3059 372.3761,-157.6054 373.6504,-156.9388 375.028,-156.308 376.5046,-155.7147 378.0758,-155.1606 379.7362,-154.6472 381.48,-154.1759 383.3009,-153.7479 385.1923,-153.3645 387.1469,-153.0266 389.1571,-152.7353 391.215,-152.4913 393.3123,-152.2953 395.4406,-152.1479 397.5911,-152.0493 399.7549,-152 401.9233,-152 404.0871,-152.0493\"/>\n<text text-anchor=\"middle\" x=\"400.8391\" y=\"-166.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n</g>\n<g id=\"node2\" class=\"node\">\n<title></title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"427.8391,-86.5442 427.8391,-101.4558 412.0229,-112 389.6553,-112 373.8391,-101.4558 373.8391,-86.5442 389.6553,-76 412.0229,-76 427.8391,-86.5442\"/>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"431.8391,-84.4034 431.8391,-103.5966 413.234,-116 388.4442,-116 369.8391,-103.5966 369.8391,-84.4034 388.4442,-72 413.234,-72 431.8391,-84.4034\"/>\n</g>\n<!-- _start&#45;&gt; -->\n<g id=\"edge1\" class=\"edge\">\n<title>_start&#45;&gt;</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M400.8391,-151.9891C400.8391,-144.291 400.8391,-135.0629 400.8391,-126.2561\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"404.3392,-126.2282 400.8391,-116.2282 397.3392,-126.2282 404.3392,-126.2282\"/>\n</g>\n<!-- RandomForestClassifier -->\n<g id=\"node3\" class=\"node\">\n<title>RandomForestClassifier</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122.8391\" cy=\"-18\" rx=\"122.6784\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"122.8391\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">RandomForestClassifier</text>\n</g>\n<!-- &#45;&gt;RandomForestClassifier -->\n<g id=\"edge2\" class=\"edge\">\n<title>&#45;&gt;RandomForestClassifier</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M369.7582,-85.5031C326.6973,-73.731 247.7558,-52.1499 190.7028,-36.5527\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.6011,-33.1699 181.032,-33.9089 189.7551,-39.9221 191.6011,-33.1699\"/>\n</g>\n<!-- GradientBoostingClassifier -->\n<g id=\"node4\" class=\"node\">\n<title>GradientBoostingClassifier</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"400.8391\" cy=\"-18\" rx=\"137.2758\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"400.8391\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">GradientBoostingClassifier</text>\n</g>\n<!-- &#45;&gt;GradientBoostingClassifier -->\n<g id=\"edge3\" class=\"edge\">\n<title>&#45;&gt;GradientBoostingClassifier</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M400.8391,-71.6086C400.8391,-63.7272 400.8391,-54.7616 400.8391,-46.4482\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"404.3392,-46.3974 400.8391,-36.3975 397.3392,-46.3975 404.3392,-46.3974\"/>\n</g>\n<!-- AdaBoostClassifier -->\n<g id=\"node5\" class=\"node\">\n<title>AdaBoostClassifier</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"655.8391\" cy=\"-18\" rx=\"99.3824\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"655.8391\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">AdaBoostClassifier</text>\n</g>\n<!-- &#45;&gt;AdaBoostClassifier -->\n<g id=\"edge4\" class=\"edge\">\n<title>&#45;&gt;AdaBoostClassifier</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M431.8522,-84.7569C472.0036,-72.7902 542.8987,-51.6607 594.1931,-36.3729\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"595.2692,-39.7044 603.853,-33.4939 593.2698,-32.996 595.2692,-39.7044\"/>\n</g>\n</g>\n</svg>\n"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the server locally"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Create a mock server from the serving function\n",
    "server = fn.to_mock_server()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> 2021-08-11 06:22:36,867 [info] model RandomForestClassifier was loaded\n",
      "> 2021-08-11 06:22:36,912 [info] model GradientBoostingClassifier was loaded\n",
      "> 2021-08-11 06:22:36,969 [info] model AdaBoostClassifier was loaded\n",
      "> 2021-08-11 06:22:36,970 [info] Loaded ['RandomForestClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View a sample of the online features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Create the online feature service\n",
    "svc = fstore.get_online_feature_service(f'{project_name}/transactions-fraud-short:latest')\n",
    "\n",
    "# Get sample feature vector\n",
    "sample_id = 'C76780537'\n",
    "sample_fv = svc.get([{'source': sample_id}])\n",
    "sample_fv"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'amount_max_2h': -inf,\n",
       "  'amount_max_12h': 32.73,\n",
       "  'amount_sum_2h': 0.0,\n",
       "  'amount_count_2h': 0.0,\n",
       "  'amount_avg_2h': nan}]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import json\n",
    "\n",
    "# Send a sample ID for predcition\n",
    "test_path = f'/v2/models/infer'\n",
    "test_sample = json.dumps({'inputs': [sample_id]})\n",
    " \n",
    "server.test(path=test_path,\n",
    "            body=test_sample)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "event body: {'inputs': ['C76780537']}\n",
      "sources: [{'source': 'C76780537'}]\n",
      "<class 'list'>\n",
      "[{'source': 'C76780537'}]\n",
      "vectors: [{'amount_max_2h': -inf, 'amount_max_12h': 32.73, 'amount_sum_2h': 0.0, 'amount_count_2h': 0.0, 'amount_avg_2h': nan}]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'id': '855eb91369024bc6ae8c407a96ca8861',\n",
       " 'model_name': [0],\n",
       " 'outputs': [0],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "test_sample"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'{\"inputs\": [\"C76780537\"]}'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test the function on the kubernetes cluster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Deploy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "addr = fn.deploy()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> 2021-08-11 06:22:37,211 [info] Starting remote function deploy\n",
      "2021-08-11 06:22:38  (info) Deploying function\n",
      "2021-08-11 06:22:38  (info) Building\n",
      "2021-08-11 06:22:39  (info) Staging files and preparing base images\n",
      "2021-08-11 06:22:39  (info) Building processor image\n",
      "2021-08-11 06:22:43  (info) Build complete\n",
      "2021-08-11 06:22:51  (info) Function deploy complete\n",
      "> 2021-08-11 06:22:52,291 [info] function deployed, address=default-tenant.app.product-v301.iguazio-cd0.com:30176\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "fn.invoke(path=test_path,\n",
    "     body=test_sample)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'id': 'c2ddeadb-5847-47b8-9fa0-99e37eb43cca',\n",
       " 'model_name': [0],\n",
       " 'outputs': [0],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stream Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import v3io\n",
    "import nuclio\n",
    "\n",
    "# create stream\n",
    "prediction_stream = f'v3io:///projects/{project_name}/streams/transaction_fraud_stream'\n",
    "client = v3io.dataplane.Client()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "client.stream.create(container='projects',\n",
    "                 stream_path=f'{project_name}/streams/transaction_fraud_stream',\n",
    "                 shard_count=2, raise_for_status=v3io.dataplane.transport.RaiseForStatus.never)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<v3io.dataplane.response.Response at 0x7ff3a8143e10>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "stream_trigger = nuclio.triggers.V3IOStreamTrigger()\n",
    "fn.add_v3io_stream_trigger(f'v3io:///projects/{project_name}/streams/transaction_fraud_stream')\n",
    "fn.deploy()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> 2021-08-11 06:30:07,400 [info] Starting remote function deploy\n",
      "2021-08-11 06:30:08  (info) Deploying function\n",
      "2021-08-11 06:30:08  (info) Building\n",
      "2021-08-11 06:30:09  (info) Staging files and preparing base images\n",
      "2021-08-11 06:30:09  (info) Building processor image\n",
      "2021-08-11 06:30:11  (info) Build complete\n",
      "2021-08-11 06:30:19  (info) Function deploy complete\n",
      "> 2021-08-11 06:30:20,353 [info] function deployed, address=default-tenant.app.product-v301.iguazio-cd0.com:30176\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'http://default-tenant.app.product-v301.iguazio-cd0.com:30176'"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "data = {'operation': 'infer',\n",
    "        'model': 'VotingEnsemble',\n",
    "        'inputs': [sample_id]}\n",
    "\n",
    "rec = client.stream.put_records(container='projects',\n",
    "                                stream_path=f'{project_name}/streams/transaction_fraud_stream',\n",
    "                                records=[{'data': json.dumps(data)}])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "print(f'Successful records: {len(rec.output.records)}, failed records: {rec.output.failed_record_count}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successful records: 1, failed records: 0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
<a id="top"></a>
[![Build Status](https://github.com/mlrun/mlrun/workflows/CI/badge.svg)](https://github.com/mlrun/mlrun/actions)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![PyPI version fury.io](https://badge.fury.io/py/mlrun.svg)](https://pypi.python.org/pypi/mlrun/)
[![Documentation](https://readthedocs.org/projects/mlrun/badge/?version=latest)](https://mlrun.readthedocs.io/en/latest/?badge=latest)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

<p align="left"><img src="docs/_static/images/MLRun-logo.png" alt="MLRun logo" width="150"/></p>

*The Open-Source MLOps Orchestration Framework*

MLRun is an open-source MLOps framework that offers an integrative approach to managing your machine-learning pipelines from early development through model development to full pipeline deployment in production.
MLRun offers a convenient abstraction layer to a wide variety of technology stacks while empowering data engineers and data scientists to define the feature and models.


## Architecture 

![pipeline](./docs/_static/images/pipeline.png)

MLRun is composed of the following layers:

- **[Feature Store](./docs/feature-store/feature-store.html)** &mdash; collects, prepares, catalogs, and serves data features for development (offline) and real-time (online) usage for real-time and batch data. See also 
[Feature store: data ingestion](./docs/feature-store/feature-store-data-ingestion) and [Feature store: data retrieval](./docs/feature-store/feature-store-data-retrieval), as well as the [Feature Store tutorials](./docs/feature-store/feature-store-tutorials).
- **[ML CI/CD pipeline](.docs//projects/ci-integration)** &mdash; automatically trains, tests, optimizes, and deploys or updates models using a snapshot of the production 
data (generated by the feature store) and code from the source control (Git).
- **[Real-Time Serving Pipeline](./docs/serving/serving-graph)** &mdash; Rapid deployment of scalable data and ML pipelines using real-time serverless technology, including 
the API handling, data preparation/enrichment, model serving, ensembles, driving and measuring actions, etc.
- **[Real-Time monitoring and retraining](.docs//model_monitoring/index)** &mdash; monitors data, models, and production components and provides a feedback loop for exploring production data, identifying drift, alerting on anomalies or data quality issues, triggering re-training jobs, measuring business impact, etc.

## Get started

Start by: 
1. Installing MLRun using one of:
   - [Installing MLRun on a Kubernetes Cluster](https://docs.mlrun.org/en/latest/install/kubernetes)
   - [Install MLRun locally using Docker](https://docs.mlrun.org/en/latest/install/local-docker)
   - Or by [Using the iguazio platform](https://www.iguazio.com/docs/latest-release/)
2. Set up your client environment to work with the service, by one of: 
      - Setting the MLRun path env variable to `MLRUN_DBPATH=http://localhost:8080` 
      - Using [`.env` files](https://docs.mlrun.org/en/latest/install/remote)
      - Using an [MLRun Jupyter image](https://docs.mlrun.org/en/latest/install/local-docker.html#use-mlrun-with-mlrun-jupyter-image)
3. Continue by using the Quick start guide, watching the [Tutorial on Youtube](https://www.youtube.com/embed/O6g1pJJ609U), and using the [MLRun Katakoda Scenarios](https://www.katacoda.com/mlrun) for hands-on tutorials<br>.
   Also, read more in the MLRun documentation, including:
      - [What is MLRun?](https://docs.mlrun.org/en/latest/index.html)
      - [Quick-Start Guide](https://docs.mlrun.org/en/latest/quick-start/quick-start.html)
      - [Tutorials and examples](https://docs.mlrun.org/en/latest/howto/index.html)
      - [Installation and setup guide](https://docs.mlrun.org/en/latest/install.html)
      - [Projects](https://docs.mlrun.org/en/latest/projects/project.html)
      - [MLRun serverless functions](https://docs.mlrun.org/en/latest/concepts/functions-concepts.html)
      - [Data stores and data items](https://docs.mlrun.org/en/latest/concepts/data-feature-store.html)
      - [Feature store](https://docs.mlrun.org/en/latest/feature-store/feature-store.html)
      - [Runs, functions, and workflows](https://docs.mlrun.org/en/latest/concepts/runs-experiments-workflows.html)
      - [Artifacts and models](https://docs.mlrun.org/en/latest/store/artifacts.html)
      - [Deployment and monitoring](https://docs.mlrun.org/en/latest/concepts/deployment-monitoring.html)
      - Feature store
         - [Data ingestion](https://docs.mlrun.org/en/latest/feature-store/feature-store-data-ingestion.html)
         - [Data retrieval](https://docs.mlrun.org/en/latest/feature-store/feature-store-data-retrieval.html)
         - [Tutorials](https://docs.mlrun.org/en/latest/feature-store/feature-store-tutorials.html)
      - [Creating and using functions](https://docs.mlrun.org/en/latest/runtimes/functions.html)
      - [Run, track, and compare jobs](https://docs.mlrun.org/en/latest/runtimes/run-track-compare-jobs.html)
      - [Real-time serving pipelines (graphs)](https://docs.mlrun.org/en/latest/serving/serving-graph.html)
      - [Model serving pipelines](https://docs.mlrun.org/en/latest/serving/build-graph-model-serving.html)
      - [CI/CD, rolling upgrades, git](https://docs.mlrun.org/en/latest/model_monitoring/ci-cd-rolling-upgrades-git.html)
      - [API](https://docs.mlrun.org/en/latest/api/index.html)
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Serving\n",
    "In this part we will user MLRun's **serving runtime** to deploy our trained models from the previous stage a `Voting Ensemble` using **max vote** logic.  \n",
    "We will also use MLRun's **Feature store** to receive the online **Feature Vector** we define in the preveious stage.\n",
    "\n",
    "We will:\n",
    "- Define a model class to load our models, run preprocessing and predict on the data\n",
    "- Define Voting Ensemble function on top of our models\n",
    "- Test the serving function locally using our `mock server`\n",
    "- Deploy the function to the cluster and test it live\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Since our work is done in a this project scope, we will first want to define the project itself for all our MLRun work in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "project, _ = mlrun.set_environment(project='fraud-demo', user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Class\n",
    "- Load models\n",
    "- Predict from the FS Online service via the `source` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudpickle import load\n",
    "import numpy as np\n",
    "import mlrun\n",
    "import os\n",
    "\n",
    "class ClassifierModel(mlrun.serving.V2ModelServer):\n",
    "    \n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "        model_file, extra_data = self.get_model('.pkl')\n",
    "        self.model = load(open(model_file, 'rb'))\n",
    "        \n",
    "        # Setup FS Online service\n",
    "        self.feature_service = mlrun.feature_store.get_online_feature_service('transactions-fraud')\n",
    "        \n",
    "        # Get feature vector statistics for imputing\n",
    "        self.feature_stats = self.feature_service.vector.get_stats_table()\n",
    "        \n",
    "        # Default category\n",
    "        self.default_category = 0\n",
    "        \n",
    "    def preprocess(self, body: dict, op) -> list:\n",
    "        # Get patient feature vector \n",
    "        # from the patient_id given in the request\n",
    "        vectors = self.feature_service.get([{'source': source} for source in body['inputs']])\n",
    "        \n",
    "        # Impute inf's in the data to the feature's mean value\n",
    "        # using the collected statistics from the Feature store\n",
    "        feature_vectors = []\n",
    "        for fv in vectors:\n",
    "            new_vec = []\n",
    "            for f, v in fv.items():\n",
    "                if type(v) == float:\n",
    "                    if np.isinf(v) or np.isnan(v):\n",
    "                        new_vec.append(self.feature_stats.loc[f, 'mean'])\n",
    "                    else:\n",
    "                        new_vec.append(v)\n",
    "                elif v == None:\n",
    "                    new_vec.append(self.default_category)\n",
    "                else:\n",
    "                    new_vec.append(v)\n",
    "            feature_vectors.append(new_vec)\n",
    "            \n",
    "        # Set the final feature vector as our inputs\n",
    "        # to pass to the predict function\n",
    "        body['inputs'] = feature_vectors\n",
    "        return body\n",
    "\n",
    "    def predict(self, body: dict) -> list:\n",
    "        \"\"\"Generate model predictions from sample\"\"\"\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        result: np.ndarray = self.model.predict(feats)\n",
    "        return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Serving Function\n",
    "- Gather ClassifierModel code from this notebook\n",
    "- Define `VotingEnsemble` - Max-Vote based ensemble\n",
    "- Add downloaded models to the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"890pt\" height=\"196pt\"\n",
       " viewBox=\"0.00 0.00 890.28 196.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 192)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-192 886.2757,-192 886.2757,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"410.4874,-152.0493 412.6379,-152.1479 414.7661,-152.2953 416.8634,-152.4913 418.9213,-152.7353 420.9315,-153.0266 422.8861,-153.3645 424.7775,-153.7479 426.5985,-154.1759 428.3423,-154.6472 430.0026,-155.1606 431.5738,-155.7147 433.0505,-156.308 434.428,-156.9388 435.7024,-157.6054 436.87,-158.3059 437.928,-159.0385 438.8741,-159.8012 439.7067,-160.5918 440.4247,-161.4082 441.0276,-162.2481 441.5156,-163.1093 441.8894,-163.9894 442.15,-164.886 442.2993,-165.7965 442.3395,-166.7186 442.2732,-167.6497 442.1034,-168.5873 441.8335,-169.5287 441.4674,-170.4713 441.0089,-171.4127 440.4623,-172.3503 439.8321,-173.2814 439.1229,-174.2035 438.3394,-175.114 437.4862,-176.0106 436.5683,-176.8907 435.5902,-177.7519 434.5568,-178.5918 433.4727,-179.4082 432.3422,-180.1988 431.1697,-180.9615 429.9595,-181.6941 428.7153,-182.3946 427.441,-183.0612 426.14,-183.692 424.8156,-184.2853 423.4707,-184.8394 422.1082,-185.3528 420.7306,-185.8241 419.3401,-186.2521 417.9387,-186.6355 416.5284,-186.9734 415.1106,-187.2647 413.687,-187.5087 412.2587,-187.7047 410.827,-187.8521 409.3929,-187.9507 407.9573,-188 406.5213,-188 405.0858,-187.9507 403.6517,-187.8521 402.2199,-187.7047 400.7917,-187.5087 399.368,-187.2647 397.9503,-186.9734 396.5399,-186.6355 395.1386,-186.2521 393.7481,-185.8241 392.3704,-185.3528 391.0079,-184.8394 389.6631,-184.2853 388.3387,-183.692 387.0377,-183.0612 385.7634,-182.3946 384.5192,-181.6941 383.3089,-180.9615 382.1365,-180.1988 381.006,-179.4082 379.9218,-178.5918 378.8884,-177.7519 377.9104,-176.8907 376.9924,-176.0106 376.1393,-175.114 375.3557,-174.2035 374.6465,-173.2814 374.0163,-172.3503 373.4698,-171.4127 373.0113,-170.4713 372.6451,-169.5287 372.3753,-168.5873 372.2055,-167.6497 372.1391,-166.7186 372.1793,-165.7965 372.3286,-164.886 372.5893,-163.9894 372.963,-163.1093 373.451,-162.2481 374.0539,-161.4082 374.7719,-160.5918 375.6045,-159.8012 376.5507,-159.0385 377.6087,-158.3059 378.7763,-157.6054 380.0506,-156.9388 381.4282,-156.308 382.9049,-155.7147 384.476,-155.1606 386.1364,-154.6472 387.8802,-154.1759 389.7012,-153.7479 391.5926,-153.3645 393.5472,-153.0266 395.5574,-152.7353 397.6153,-152.4913 399.7126,-152.2953 401.8408,-152.1479 403.9913,-152.0493 406.1552,-152 408.3235,-152 410.4874,-152.0493\"/>\n",
       "<text text-anchor=\"middle\" x=\"407.2393\" y=\"-166.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n",
       "</g>\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title></title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"434.2393,-86.5442 434.2393,-101.4558 418.4231,-112 396.0556,-112 380.2393,-101.4558 380.2393,-86.5442 396.0556,-76 418.4231,-76 434.2393,-86.5442\"/>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"438.2393,-84.4034 438.2393,-103.5966 419.6342,-116 394.8445,-116 376.2393,-103.5966 376.2393,-84.4034 394.8445,-72 419.6342,-72 438.2393,-84.4034\"/>\n",
       "</g>\n",
       "<!-- _start&#45;&gt; -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M407.2393,-151.9891C407.2393,-144.291 407.2393,-135.0629 407.2393,-126.2561\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"410.7394,-126.2282 407.2393,-116.2282 403.7394,-126.2282 410.7394,-126.2282\"/>\n",
       "</g>\n",
       "<!-- 1&#45;transaction_fraud__rf -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1&#45;transaction_fraud__rf</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"120.2393\" cy=\"-18\" rx=\"120.4791\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"120.2393\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1&#45;transaction_fraud__rf</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;1&#45;transaction_fraud__rf -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>&#45;&gt;1&#45;transaction_fraud__rf</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M375.979,-85.722C331.4588,-73.9327 248.6192,-51.9961 189.2779,-36.282\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.1592,-32.8948 179.5964,-33.7183 188.3673,-39.6616 190.1592,-32.8948\"/>\n",
       "</g>\n",
       "<!-- 2&#45;transaction_fraud__xgboost -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2&#45;transaction_fraud__xgboost</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"407.2393\" cy=\"-18\" rx=\"148.6738\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"407.2393\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2&#45;transaction_fraud__xgboost</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;2&#45;transaction_fraud__xgboost -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>&#45;&gt;2&#45;transaction_fraud__xgboost</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M407.2393,-71.6086C407.2393,-63.7272 407.2393,-54.7616 407.2393,-46.4482\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"410.7394,-46.3974 407.2393,-36.3975 403.7394,-46.3975 410.7394,-46.3974\"/>\n",
       "</g>\n",
       "<!-- 3&#45;transaction_fraud__adaboost -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3&#45;transaction_fraud__adaboost</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"728.2393\" cy=\"-18\" rx=\"154.0727\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"728.2393\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3&#45;transaction_fraud__adaboost</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;3&#45;transaction_fraud__adaboost -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>&#45;&gt;3&#45;transaction_fraud__adaboost</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M438.3098,-86.6437C486.8238,-75.1576 582.0537,-52.6109 650.1386,-36.4911\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"651.0536,-39.8713 659.9782,-34.1615 649.4408,-33.0596 651.0536,-39.8713\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe724a17450>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import auto_mount\n",
    "\n",
    "# Create the serving function from our code above\n",
    "fn = mlrun.code_to_function('transaction-fraud', kind='serving', image=\"mlrun/mlrun\")\n",
    "\n",
    "# Apply a mount so we can load the model files directly from the v3io fs\n",
    "fn.apply(auto_mount())\n",
    "\n",
    "# Set the Voting Ensemble as our router\n",
    "fn.set_topology('router', 'mlrun.serving.VotingEnsemble', name='Transactionfraud')\n",
    "\n",
    "# Add the three previously trained models to the ensemble\n",
    "models_dir = os.path.abspath('models')\n",
    "for name in ['1-transaction_fraud__rf', '2-transaction_fraud__xgboost', '3-transaction_fraud__adaboost']:\n",
    "    fn.add_model(name, class_name=\"ClassifierModel\", model_path=f\"store://artifacts/{project}/training_model:latest\")\n",
    "    \n",
    "# Plot the ensemble configuration\n",
    "fn.spec.graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the server locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-06-06 09:22:20,445 [info] model 1-transaction_fraud__rf was loaded\n",
      "> 2021-06-06 09:22:20,598 [info] model 2-transaction_fraud__xgboost was loaded\n",
      "> 2021-06-06 09:22:20,746 [info] model 3-transaction_fraud__adaboost was loaded\n",
      "> 2021-06-06 09:22:20,746 [info] Loaded ['1-transaction_fraud__rf', '2-transaction_fraud__xgboost', '3-transaction_fraud__adaboost']\n"
     ]
    }
   ],
   "source": [
    "# Create a mock server from the serving function\n",
    "server = fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2a111836ff5347a1ad815468ce32ff24',\n",
       " 'model_name': [0],\n",
       " 'outputs': [0],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Send a sample ID for predcition\n",
    "server.test(path='/v2/models/infer',\n",
    "            body=json.dumps({'inputs': ['C2054744914']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the function on the kubernetes cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-06-06 09:22:20,852 [info] Starting remote function deploy\n",
      "2021-06-06 09:22:21  (info) Deploying function\n",
      "2021-06-06 09:22:21  (info) Building\n",
      "2021-06-06 09:22:21  (info) Staging files and preparing base images\n",
      "2021-06-06 09:22:21  (info) Building processor image\n",
      "2021-06-06 09:22:22  (info) Build complete\n",
      "> 2021-06-06 09:22:30,613 [info] function deployed, address=default-tenant.app.dev6.lab.iguazeng.com:31730\n"
     ]
    }
   ],
   "source": [
    "addr = fn.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ed0169f4-674d-4dbf-b60a-b6b831067d61',\n",
       " 'model_name': [0],\n",
       " 'outputs': [0],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.invoke(path='/v2/models/infer',\n",
    "          body=json.dumps({'inputs': ['C2054744914']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

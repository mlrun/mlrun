{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Pipeline Automation  \n",
    "\n",
    "This part of the feature store demo walks you through the steps for creating an automated pipeline for our project.\n",
    "The pipeline is created using [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/pipelines-quickstart/).\n",
    "\n",
    "The integration of MLRun with Kubeflow Pipelines enables you to take the functions in your project and build a pipeline that contains these functions.\n",
    "\n",
    "> **Note**: The Iguazio Data Science Platform has a default (pre-deployed) shared Kubeflow Pipelines service (`pipelines`).\n",
    "\n",
    "An ML Engineer can gather the different functions created by the Data Engineer and Data Scientist and create this automated pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "\n",
    "project_name, _ = mlrun.set_environment(project='fraud-demo', \n",
    "                                        user_project=True, artifact_path='./artifact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlrun_project = mlrun.new_project(project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Fully Automated ML Pipeline\n",
    "\n",
    "#### Add more functions to our project to be used in our pipeline (from the functions hub/marketplace)\n",
    "\n",
    "AutoML training (classifier), Model validation (test_classifier), Real-time model server, and Model REST API Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f1b87a9c7d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlrun_project.set_function('hub://describe')\n",
    "mlrun_project.set_function('hub://sklearn_classifier', 'train')\n",
    "mlrun_project.set_function('hub://test_classifier', 'test')\n",
    "mlrun_project.set_function('hub://v2_model_server', 'serving')\n",
    "mlrun_project.set_function('hub://v2_model_tester', 'live_tester')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and save a pipeline \n",
    "\n",
    "The following workflow definition will be written into a file, it describes a Kubeflow execution graph (DAG)<br>\n",
    "and how functions and data are connected  to form an end to end pipeline. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflow.py\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "\n",
    "funcs = {}\n",
    "\n",
    "model_list = {\"model_name\": ['transaction_fraud_rf','transaction_fraud_xgboost', \n",
    "                             'transaction_fraud_adaboost'],\n",
    "              \n",
    "              \"model_pkg_class\": ['sklearn.ensemble.RandomForestClassifier',\n",
    "                                  'sklearn.ensemble.GradientBoostingClassifier',\n",
    "                                  'sklearn.ensemble.AdaBoostClassifier']}\n",
    "\n",
    "\n",
    "# init functions is used to configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "    \n",
    "@dsl.pipeline(\n",
    "    name=\"Demo training pipeline\",\n",
    "    description=\"Shows how to use mlrun.\"\n",
    ")\n",
    "def kfpipeline(vector, label):\n",
    "       \n",
    "    # analyze our dataset\n",
    "    describe = funcs[\"describe\"].as_step(\n",
    "        name=\"summary\",\n",
    "        params={\"label_column\": label},\n",
    "        inputs={\"table\": vector})\n",
    "    \n",
    "    # train with hyper-paremeters \n",
    "    train = funcs[\"train\"].as_step(\n",
    "        name=\"train\",\n",
    "        params={\"label_column\": label},\n",
    "        hyperparams=model_list,\n",
    "        selector='max.accuracy',\n",
    "        inputs={\"dataset\"         : vector},\n",
    "        outputs=['model', 'test_set'])\n",
    "\n",
    "    # test and visualize our model\n",
    "    test = funcs[\"test\"].as_step(\n",
    "        name=\"test\",\n",
    "        params={\"label_column\": label},\n",
    "        inputs={\"models_path\" : train.outputs['model'],\n",
    "                \"test_set\"    : train.outputs['test_set']})\n",
    "\n",
    "    # deploy our model as a serverless function, we can pass a list of models to serve \n",
    "    deploy = funcs[\"serving\"].deploy_step(models=[{\"key\": f\"fraud:v1\", \"model_path\": train.outputs['model']}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the workflow file as \"main\", embed the workflow code into the project YAML\n",
    "mlrun_project.set_workflow('main', 'workflow.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the project definitions to a file (project.yaml), it is recommended to commit all changes to a Git repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlrun_project.save(\"project.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-pipeline'></a>\n",
    "## Run a pipeline workflow\n",
    "use the `run` method to execute a workflow, you can provide alternative arguments and specify the default target for workflow artifacts.<br>\n",
    "The workflow ID is returned and can be used to track the progress or you can use the hyperlinks\n",
    "\n",
    "> Note: The same command can be issued through CLI commands:<br>\n",
    "    `mlrun project my-proj/ -r main -p \"v3io:///users/admin/mlrun/kfp/{{workflow.uid}}/\"`\n",
    "\n",
    "The `dirty` flag allow us to run a project with uncommited changes (when the notebook is in the same git dir it will always be dirty)<br>\n",
    "The `watch` flag will wait for the pipeline to complete and print results\n",
    "\n",
    "In this cell we will run the `main` workflow via `KubeFlow Pipelines` on top of our cluster.  \n",
    "Running the pipeline may take some time. Due to possible jupyter timeout, it's best to track the pipeline's progress via KFP or the MLRun UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-08-11 06:37:14,549 [info] using in-cluster config.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.product-v301.iguazio-cd0.com/pipelines/#/experiments/details/b85fc39f-3ff9-4624-aa7d-c37acb0d86d7\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.product-v301.iguazio-cd0.com/pipelines/#/runs/details/e9d00261-3939-43a7-8bb2-2a26bba14d97\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-08-11 06:37:15,078 [info] Pipeline run id=e9d00261-3939-43a7-8bb2-2a26bba14d97, check UI or DB for progress\n",
      "> 2021-08-11 06:37:15,079 [info] waiting for pipeline run completion\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "\n",
    "vector = f'store://feature-vectors/{project_name}/transactions-fraud'\n",
    "\n",
    "artifact_path = path.abspath('./pipe/{{workflow.uid}}')\n",
    "run_id = mlrun_project.run(\n",
    "    'main',\n",
    "    arguments={'vector': vector, 'label': 'label'}, \n",
    "    artifact_path=artifact_path, \n",
    "    dirty=True, watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[back to top](#top)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

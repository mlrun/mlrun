{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Projects and Automated ML Pipeline\n",
    "\n",
    "This part of the MLRun getting-started tutorial walks you through the steps for working with projects, source control (git), and automating the ML pipeline.\n",
    "\n",
    "MLRun Project is a container for all your work on a particular activity: all the associated code, functions, \n",
    "jobs/workflows and artifacts. Projects can be mapped to `git` repositories to enable versioning, collaboration, and CI/CD.\n",
    "\n",
    "You can create project definitions using the SDK or a yaml file and store those in MLRun DB, file, or archive.\n",
    "Once the project is loaded you can run jobs/workflows which refer to any project element by name, allowing separation between configuration and code. See [Create and load projects](../projects/create-load-import-project.md) for details.\n",
    "\n",
    "Projects contain `workflows` that execute the registered functions in a sequence/graph (DAG), and which can reference project parameters, secrets and artifacts by name. MLRun currently supports two workflow engines, `local` (for simple tasks) and [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/pipelines-quickstart/) (for more complex/advanced tasks). MLRun also supports a real-time workflow engine (see [MLRun serving graphs](../serving/serving-graph.md)). \n",
    "\n",
    "> **Note**: The Iguazio MLOps Platform has a default (pre-deployed) shared Kubeflow Pipelines service (`pipelines`).\n",
    "\n",
    "An ML Engineer can gather the different functions created by the Data Engineer and Data Scientist and create this automated pipeline.\n",
    "\n",
    "The tutorial consists of the following steps:\n",
    "\n",
    "1. [Setting up Your Project](#gs-tutorial-4-step-setting-up-project)\n",
    "2. [Updating Project and Function Definitions](#gs-tutorial-4-step-import-functions)\n",
    "3. [Defining and Saving a Pipeline Workflow](#gs-tutorial-4-step-pipeline-workflow-define-n-save)\n",
    "4. [Registering the Workflow](#gs-tutorial-4-step-register-workflow)\n",
    "5. [Running A Pipeline](#gs-tutorial-4-step-run-pipeline)\n",
    "6. [Viewing the Pipeline on the Dashboard (UI)](#gs-tutorial-4-step-ui-pipeline-view)\n",
    "7. [Invoking the Model](#gs-tutorial-4-step-invoke-model)\n",
    "\n",
    "By the end of this tutorial you'll learn how to:\n",
    "\n",
    "- Create an operational pipeline using previously defined functions.\n",
    "- Run the pipeline and track the pipeline results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-prerequisites\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are a continuation of the previous parts of this getting-started tutorial and rely on the generated outputs.\n",
    "Therefore, make sure to first run parts [1](01-mlrun-basics.ipynb)&mdash;[3](03-model-serving.ipynb) of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-step-setting-up-project\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setting Up Your Project\n",
    "\n",
    "To run a pipeline, you first need to create a Python project object and import the required functions for its execution.\n",
    "\n",
    "Create a project by using one of:\n",
    "\n",
    "- the `new_project` MLRun method\n",
    "- the `get_or_create_project`method: loads a project from the MLRun DB or the archive/context if it exists, or creates a new project if it doesn't exist.\n",
    "\n",
    "Both methods have the following parameters:\n",
    "\n",
    "- **`name`** (required) &mdash; the project name.\n",
    "- **`context`** &mdash; the path to a local project directory (the project's context directory).\n",
    "  The project directory contains a project-configuration file (default: **project.yaml**) that defines the project, and additional generated Python code.\n",
    "  The project file is created when you save your project (using the `save` MLRun project method or when saving your first function within the project).\n",
    "- **`init_git`** &mdash; set to `True` to perform Git initialization of the project directory (`context`) in case its not initialized.\n",
    "  > **Note:** It's customary to store project code and definitions in a Git repository.\n",
    "\n",
    "The following code gets or creates a user project named \"getting-started-&lt;username&gt;\".\n",
    "\n",
    "> **Note:** Platform projects are currently shared among all users of the parent tenant, to facilitate collaboration. Therefore:\n",
    ">\n",
    "> - Set `user_project` to `True` if you want to create a project unique to your user.\n",
    ">   You can easily change the default project name for this tutorial by changing the definition of the `project_name_base` variable in the following code.\n",
    "> - Don't include in your project proprietary information that you don't want to expose to other users.\n",
    ">   Note that while projects are a useful tool, you can easily develop and run code in the platform without using projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-02-08 22:48:12,960 [info] loaded project getting-started from MLRun DB\n",
      "Full project name: getting-started-admin\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "# Set the base project name\n",
    "project_name_base = 'getting-started'\n",
    "\n",
    "# Initialize the MLRun project object\n",
    "project = mlrun.get_or_create_project(project_name_base, context=\"./\", user_project=True, init_git=True)\n",
    "\n",
    "print(f'Full project name: {project.metadata.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-step-import-functions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Updating Project and Function Definitions\n",
    "\n",
    "You must save the definitions for the functions used in the project so that you can automatically convert code to functions, import external functions when you load new versions of MLRun code, or run automated CI/CD workflows. In addition, you might want to set other project attributes such as global parameters, secrets, and data.\n",
    "\n",
    "The code can be stored in Python files, notebooks, external repositories, packaged containers, etc. Use the `project.set_function()` method to register the code in the project. The definitions are saved to the project object as well as in a YAML file in the root of the project.\n",
    "Functions can also be imported from MLRun marketplace (using the `hub://` schema).\n",
    "\n",
    "This tutorial uses the functions:\n",
    "- `prep-data` &mdash; the first function, which ingests the Iris data set (in Notebook 01)\n",
    "- `describe` &mdash; generates statistics on the data set (from the marketplace)\n",
    "- `train-iris` &mdash; the model-training function (in Notebook 02)\n",
    "- `test-classifier` &mdash; the model-testing function (from the marketplace)\n",
    "- `mlrun-model` &mdash; the model-serving function (in Notebook 03)\n",
    "\n",
    "> Note: `set_function` uses the `code_to_function` and `import_function` methods under the hood (used in the previous notebooks), but in addition it saves the function configurations in the project spec for use in automated workflows and CI/CD. \n",
    "\n",
    "Add the function definitions to the project along with parameters and data artifacts, and save the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-view-project-functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_function('01-mlrun-basics.ipynb', 'prep-data', kind='job', image='mlrun/mlrun')\n",
    "project.set_function('02-model-training.ipynb', 'train', kind='job', image='mlrun/mlrun', handler='train_iris')\n",
    "\n",
    "# set project level parameters and save\n",
    "project.spec.params = {'label_column': 'label'}\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>When you save the project it stores the project definitions in the `project.yaml`. This means that you can load the project from the source control (GIT) and run it with a single command or API call.\n",
    "\n",
    "The project YAML for this project can be printed using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: project\n",
      "metadata:\n",
      "  name: getting-started-admin\n",
      "  created: '2022-02-06T17:00:53.057000+00:00'\n",
      "spec:\n",
      "  params:\n",
      "    label_column: label\n",
      "  functions:\n",
      "  - url: 01-mlrun-basics.ipynb\n",
      "    name: prep-data\n",
      "    kind: job\n",
      "    image: mlrun/mlrun\n",
      "  - url: 02-model-training.ipynb\n",
      "    name: train\n",
      "    kind: job\n",
      "    image: mlrun/mlrun\n",
      "    handler: train_iris\n",
      "  workflows:\n",
      "  - name: main\n",
      "    path: workflow.py\n",
      "    engine: null\n",
      "  artifacts: []\n",
      "  source: ''\n",
      "  subpath: ''\n",
      "  origin_url: ''\n",
      "  desired_state: online\n",
      "  owner: admin\n",
      "  disable_auto_mount: false\n",
      "status:\n",
      "  state: online\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(project.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Projects from GIT\n",
    "\n",
    "After you save the project and its elements (functions, workflows, artifacts, etc.) you can commit all the changes to a GIT repository. Use the standard GIT tools or use the MLRun `project` methods such as `pull`, `push`, `remote`, which call the Git API for you.\n",
    "\n",
    "Projects can then be loaded from GIT using the MLRun `load_project` method, for example: \n",
    "\n",
    "    project = mlrun.load_project(\"./myproj\", \"git://github.com/mlrun/project-demo.git\", name=project_name)\n",
    "    \n",
    "or using MLRun CLI:\n",
    "\n",
    "    mlrun project -n myproj -u \"git://github.com/mlrun/project-demo.git\" ./myproj\n",
    "    \n",
    "Read [Create and load projects](../projects/create-load-import-project.md) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-kubeflow-pipelines\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Kubeflow Pipelines\n",
    "\n",
    "You're now ready to create a full ML pipeline.\n",
    "This is done by using [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/) &mdash;\n",
    "an open-source framework for building and deploying portable, scalable machine-learning workflows based on Docker containers.\n",
    "MLRun leverages this framework to take your existing code and deploy it as steps in the pipeline.\n",
    "\n",
    "> **Note:** When using the Iguazio MLOps Platform, Kubeflow Pipelines is available as a default (pre-deployed) shared platform service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-step-pipeline-workflow-define-n-save\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Defining and Saving a Pipeline Workflow\n",
    "\n",
    "A pipeline is created by running an MLRun **\"workflow\"**.\n",
    "The following code defines a workflow and writes it to a file in your local directory, with the file name **workflow.py**.\n",
    "The workflow describes a directed acyclic graph (DAG) for execution using Kubeflow Pipelines, and depicts the connections between the functions and the data as part of an end-to-end pipeline.\n",
    "The workflow file has two parts: initialization of the function objects, and definition of a pipeline DSL (domain-specific language) for connecting the function inputs and outputs.\n",
    "Examine the code to see how function objects are initialized and used (by name) within the workflow.\n",
    "\n",
    "The defined pipeline includes the following steps:\n",
    "\n",
    "- Ingest the Iris flower data set (`ingest`).\n",
    "- Train and the model (`train`).\n",
    "- Test the model with its test data set.\n",
    "- Deploy the model as a real-time serverless function (`deploy`).\n",
    "\n",
    "> **Note**: A pipeline can also include continuous build integration and deployment (CI/CD) steps, such as building container images and deploying models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile './workflow.py'\n",
    "\n",
    "from kfp import dsl\n",
    "import mlrun\n",
    "\n",
    "DATASET = 'cleaned_data'\n",
    "\n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(\n",
    "    name=\"Getting-started-tutorial\",\n",
    "    description=\"Demonstrate some of the main capabilities of MLRun\"\n",
    ")\n",
    "def kfpipeline(source_url, model_name=\"iris\"):\n",
    "    project = mlrun.get_current_project()\n",
    "\n",
    "    # Ingest the data set\n",
    "    ingest = mlrun.run_function(\n",
    "        'prep-data',\n",
    "        handler='prep_data',\n",
    "        inputs={'source_url': source_url},\n",
    "        params={'label_column': project.get_param(\"label_column\")},\n",
    "        outputs=[DATASET])\n",
    "    \n",
    "    # Train a model   \n",
    "    train = mlrun.run_function(\n",
    "        \"train\",\n",
    "        params={\"label_column\": project.get_param(\"label_column\")},\n",
    "        inputs={\"dataset\": ingest.outputs[DATASET]},\n",
    "        outputs=['model', 'test_set'])\n",
    "    \n",
    "    # Test and visualize the model\n",
    "    test = mlrun.run_function(\n",
    "        \"hub://test_classifier\",\n",
    "        params={\"label_column\": project.get_param(\"label_column\")},\n",
    "        inputs={\"models_path\": train.outputs['model'],\n",
    "                \"test_set\": train.outputs['test_set']})\n",
    "    \n",
    "    # Deploy the model as a serverless function\n",
    "    serving = mlrun.import_function(\"hub://v2_model_server\", new_name=\"serving\")\n",
    "    deploy = mlrun.deploy_function(serving,\n",
    "                                   models=[{\"key\":model_name, \"model_path\": train.outputs['model']}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-step-register-workflow\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Registering the Workflow\n",
    "\n",
    "Use the `set_workflow` MLRun project method to register your workflow with MLRun.\n",
    "The following code sets the `name` parameter to the selected workflow name (\"main\") and the `code` parameter to the name of the workflow file that is found in your project directory (**workflow.py**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'workflow.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-step-run-pipeline\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Running A Pipeline\n",
    "\n",
    "First run the following code to save your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `run` MLRun project method to execute your workflow pipeline with Kubeflow Pipelines.\n",
    "The tutorial code sets the following method parameters; (for the full parameters list, see the [MLRun documentation](../api/mlrun.run.html#mlrun.run.run_pipeline) or embedded help):\n",
    "\n",
    "- **`name`** &mdash; the workflow name (in this case, \"main\" &mdash; see the previous step).\n",
    "- **`arguments`** &mdash; A dictionary of Kubeflow Pipelines arguments (parameters).\n",
    "  The tutorial code sets this parameter to an empty arguments list (`{}`), but you can edit the code to add arguments.\n",
    "- **`artifact_path`** &mdash; a path or URL that identifies a location for storing the workflow artifacts.\n",
    "  You can use `{{workflow.uid}}` in the path to signify the ID of the current workflow run iteration.\n",
    "  The tutorial code sets the artifacts path to a **&lt;worker ID&gt;** directory (`{{workflow.uid}}`) in a **pipeline** directory under the projects container (**/v3io/projects/getting-started-tutorial-project name/pipeline/&lt;worker ID&gt;**).\n",
    "- **`dirty`** &mdash; set to `True` to allow running the workflow also when the project's Git repository is dirty (i.e., contains uncommitted changes).\n",
    "  (When the notebook that contains the execution code is in the same Git directory as the executed workflow, the directory is always dirty during the execution.)\n",
    "- **`watch`** &mdash; set to `True` to wait for the pipeline to complete and output the execution graph as it updates.\n",
    "\n",
    "The `run` method returns the ID of the executed workflow, which the code stores in a `run_id` variable.\n",
    "You can use this ID to track the progress or your workflow, as demonstrated in the following sections.\n",
    "\n",
    "> **Note**: You can also run the workflow from a command-line shell by using the `mlrun` CLI.\n",
    "> The following CLI command defines a similar execution logic as that of the `run` call in the tutorial:\n",
    "> ```\n",
    "> mlrun project /User/getting-started-tutorial/conf -r main -p \"$V3IO_HOME_URL/getting-started-tutorial/pipeline/{{workflow.uid}}/\"\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_url = mlrun.get_sample_path(\"data/iris/iris.data.raw.csv\")\n",
    "model_name=\"iris\"\n",
    "\n",
    "# when not using a managed cluster run with \"local\" engine (assume no Kubeflow)\n",
    "engine = \"kfp\" if mlrun.mlconf.remote_host else \"local\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>Pipeline running (id=d4fcf445-abf2-4c1e-81c3-60182df7975a), <a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd1.com/mlprojects/getting-started-admin/jobs/monitor-workflows/workflow/d4fcf445-abf2-4c1e-81c3-60182df7975a\" target=\"_blank\"><b>click here</b></a> to view the details in MLRun UI</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: kfp Pages: 1 -->\n",
       "<svg width=\"296pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 296.09 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>kfp</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 292.0934,-184 292.0934,4 -4,4\"/>\n",
       "<!-- getting&#45;started&#45;tutorial&#45;vctdx&#45;3139466320 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>getting&#45;started&#45;tutorial&#45;vctdx&#45;3139466320</title>\n",
       "<polygon fill=\"#00ff00\" stroke=\"#000000\" points=\"122,-36 4,-36 0,-32 0,0 118,0 122,-4 122,-36\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"118,-32 0,-32 \"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"118,-32 118,0 \"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"118,-32 122,-36 \"/>\n",
       "<text text-anchor=\"middle\" x=\"61\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">deploy&#45;serving</text>\n",
       "</g>\n",
       "<!-- getting&#45;started&#45;tutorial&#45;vctdx&#45;3295722836 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>getting&#45;started&#45;tutorial&#45;vctdx&#45;3295722836</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"214\" cy=\"-18\" rx=\"74.187\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"214\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">test&#45;classifier</text>\n",
       "</g>\n",
       "<!-- getting&#45;started&#45;tutorial&#45;vctdx&#45;4068437160 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>getting&#45;started&#45;tutorial&#45;vctdx&#45;4068437160</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"137\" cy=\"-90\" rx=\"33.2948\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"137\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train</text>\n",
       "</g>\n",
       "<!-- getting&#45;started&#45;tutorial&#45;vctdx&#45;4068437160&#45;&gt;getting&#45;started&#45;tutorial&#45;vctdx&#45;3139466320 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>getting&#45;started&#45;tutorial&#45;vctdx&#45;4068437160&#45;&gt;getting&#45;started&#45;tutorial&#45;vctdx&#45;3139466320</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M120.5091,-74.3771C110.861,-65.2367 98.4546,-53.4833 87.4686,-43.0755\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.8079,-40.4704 80.1412,-36.1338 84.9936,-45.5521 89.8079,-40.4704\"/>\n",
       "</g>\n",
       "<!-- getting&#45;started&#45;tutorial&#45;vctdx&#45;4068437160&#45;&gt;getting&#45;started&#45;tutorial&#45;vctdx&#45;3295722836 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>getting&#45;started&#45;tutorial&#45;vctdx&#45;4068437160&#45;&gt;getting&#45;started&#45;tutorial&#45;vctdx&#45;3295722836</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M153.7079,-74.3771C163.6267,-65.1023 176.4229,-53.137 187.6732,-42.6172\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.2468,-45.0025 195.1606,-35.6161 185.4658,-39.8895 190.2468,-45.0025\"/>\n",
       "</g>\n",
       "<!-- getting&#45;started&#45;tutorial&#45;vctdx&#45;580989947 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>getting&#45;started&#45;tutorial&#45;vctdx&#45;580989947</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"137\" cy=\"-162\" rx=\"103.1819\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"137\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prep&#45;data&#45;prep&#45;data</text>\n",
       "</g>\n",
       "<!-- getting&#45;started&#45;tutorial&#45;vctdx&#45;580989947&#45;&gt;getting&#45;started&#45;tutorial&#45;vctdx&#45;4068437160 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>getting&#45;started&#45;tutorial&#45;vctdx&#45;580989947&#45;&gt;getting&#45;started&#45;tutorial&#45;vctdx&#45;4068437160</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137,-143.8314C137,-136.131 137,-126.9743 137,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"140.5001,-118.4132 137,-108.4133 133.5001,-118.4133 140.5001,-118.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe3d1241450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Run Results</h2>Workflow d4fcf445-abf2-4c1e-81c3-60182df7975a finished, state=Succeeded<br>click the hyper links below to see detailed results<br><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"ed0e124a639e406c920077ca473a6930\"><a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd1.com/mlprojects/getting-started-admin/jobs/monitor/ed0e124a639e406c920077ca473a6930/overview\" target=\"_blank\" >...473a6930</a></div></td>\n",
       "      <td>Feb 08 22:50:08</td>\n",
       "      <td>completed</td>\n",
       "      <td>test-classifier</td>\n",
       "      <td><div class=\"dictlist\">label_column=label</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=1.0</div><div class=\"dictlist\">test-error=0.0</div><div class=\"dictlist\">auc-micro=1.0</div><div class=\"dictlist\">auc-weighted=1.0</div><div class=\"dictlist\">f1-score=1.0</div><div class=\"dictlist\">precision_score=1.0</div><div class=\"dictlist\">recall_score=1.0</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><div title=\"c22ca65ff21d493f8f1c7c394fa4647e\"><a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd1.com/mlprojects/getting-started-admin/jobs/monitor/c22ca65ff21d493f8f1c7c394fa4647e/overview\" target=\"_blank\" >...4fa4647e</a></div></td>\n",
       "      <td>Feb 08 22:49:55</td>\n",
       "      <td>completed</td>\n",
       "      <td>train</td>\n",
       "      <td><div class=\"dictlist\">label_column=label</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=1.0</div><div class=\"dictlist\">f1_score=1.0</div><div class=\"dictlist\">precision_score=1.0</div><div class=\"dictlist\">recall_score=1.0</div><div class=\"dictlist\">auc-micro=1.0</div><div class=\"dictlist\">auc-macro=1.0</div><div class=\"dictlist\">auc-weighted=1.0</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><div title=\"403e92abadd047a0a4190a7cb60d7edf\"><a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd1.com/mlprojects/getting-started-admin/jobs/monitor/403e92abadd047a0a4190a7cb60d7edf/overview\" target=\"_blank\" >...b60d7edf</a></div></td>\n",
       "      <td>Feb 08 22:49:43</td>\n",
       "      <td>completed</td>\n",
       "      <td>prep-data-prep_data</td>\n",
       "      <td><div class=\"dictlist\">label_column=label</div></td>\n",
       "      <td><div class=\"dictlist\">num_rows=150</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name=\"iris\"\n",
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={'source_url' : source_url, \"model_name\": model_name}, \n",
    "    #dirty=True,\n",
    "    engine=engine,\n",
    "    watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-step-ui-pipeline-view\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Viewing the Pipeline on the Dashboard (UI)\n",
    "\n",
    "In the **Projects > Jobs and Workflows > Monitor Workflows** tab, press the workflow name to view a graph of the workflow. Press any step to open another pane with full details of the step: either the job's overview, inputs, artifacts, etc.; or the deploy / build function's overview, code, and log. \n",
    "\n",
    "\n",
    "After the pipelines execution completes, you should be able to view the pipeline and see its functions: \n",
    "\n",
    "- `prep-data`\n",
    "- `train`\n",
    "- `test`\n",
    "- `deploy-serving`\n",
    "\n",
    "The graph is refreshed while the pipeline is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_static/images/tutorial/job_pipeline.png\" alt=\"pipeline\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-step-invoke-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Invoking the Model\n",
    "\n",
    "Now that your model is deployed using the pipeline, you can invoke it as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-02-08 22:33:07,930 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-getting-started-admin-serving.default-tenant.svc.cluster.local:8080/v2/models/iris/infer'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '1a938c32-0be5-4f6b-a468-0cfc0cb60a6a',\n",
       " 'model_name': 'iris',\n",
       " 'outputs': [0, 2]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_func = project.func('serving')  # get the latest serving function\n",
    "\n",
    "my_data = {'inputs': [[5.1, 3.5, 1.4, 0.2],[7.7, 3.8, 6.7, 2.2]]}\n",
    "serving_func.invoke(f'/v2/models/{model_name}/predict', my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make an HTTP call directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '296c0de3-0d3d-4286-84ef-ed297d15727f', 'model_name': 'iris', 'outputs': [0, 2]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "predict_url = f'http://{serving_func.status.address}/v2/models/{model_name}/predict'\n",
    "resp = requests.put(predict_url, json=json.dumps(my_data))\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-done\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "Congratulations! You've completed the getting started tutorial.\n",
    "\n",
    "You might also want to explore the following demos:\n",
    "\n",
    "- For an example of distributed training of an image-classification pipeline using TensorFlow (versions 1 or 2), Keras, and Horovod, see the [**image-classification with distributed training demo**](https://github.com/mlrun/demos/tree/release/v0.6.x-latest/image-classification-with-distributed-training).\n",
    "- To learn more about deploying live endpoints and concept drift, see the [**network-operations (NetOps) demo**](https://github.com/mlrun/demos/tree/release/v0.6.x-latest/network-operations).\n",
    "- To learn how to deploy your model with streaming information, see the [**model-deployment pipeline demo**](https://github.com/mlrun/demos/tree/release/v0.6.x-latest/model-deployment-pipeline).\n",
    "\n",
    "For additional information and guidelines, see the MLRun [**How-To Guides and Demos**](../howto/index.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

(model-monitoring-des)=# Model monitoring descriptionIn v1.6.0. MLRun introduced a {ref}`new paradigm of model monitoring <model-monitoring>`. The {ref}`legacy mode <legacy-model-monitoring>` is currently supported only for the CE version of MLRun.## Architecture<img src="../_static/images/model-monitoring.png" width="1100" ></br></br>The model monitoring process flow starts with collecting operational data from a function in the model serving pod. The model monitoring stream pod forwards data to a Parquet database. The controller periodically checks the Parquet DB for new data and forwards it to the relevant application. Each model monitoring application is a separate nuclio real-time function. Each one listens to a stream that is filled by the monitoring controller at each `base_period` interval.The stream function examines the log entry, processes it into statistics which are then written to the statistics databases (parquet file, time series database and key value database). The monitoring stream function writes the Parquet files using a basic storey ParquetTarget. Additionally, there is a monitoring feature set that refers to the same target. You can use `get_offline_features` to read the data from that feature set. When you call {py:meth}`~mlrun.projects.MlrunProject.enable_model_monitoring`, you effectively deploy three components:- application controller function: handles the monitoring processing and the triggers the apps that trigger the writer. The controller is a real-time Nuclio job whose frequency is determined by `base_period`. - stream function: monitors the log of the data stream. It is triggered when a new log entry is detected. The monitored data is used to create real-time dashboards, detect drift, and analyze performance.- writer function: writes the results and the metrics that output from the model monitoring applications to the databases, and outputs alerts according to the user configuration.## Model monitoring applicationsMLRun has a default monitoring app, `HistogramDataDriftApplication` that is tailored for classical ML models (not LLMs / gen AI / deep-learning models, etc). When you call `enable_model_monitoring` on a project, by default MLRun deploys the data drift app (`histogram-default-application`). To use a different monitoring app, disable the default data drift app (`project.enable_model_monitoring(base_period=1, deploy_histogram_data_drift_app=False)`), and follow the steps **in ??????**.You can create your own apps by first inheriting the class {py:meth}`mlrun.model_monitoring.applications.ModelMonitoringApplicationBaseV2`. </br>See example custom apps in **?????**Projects are used to group functions that use the same monitoring application. You need to create a project for each type of model: LLM, gen AI, etc., and to enable each app in its relevant project.The basic flow for classic ML and other models is the same, but the apps and the infer requests are different.## Streaming platforms and credentialsModel monitoring supports open-source streaming platforms such as Kafka, TDEngine, MySQL/SQLite, in addition to integration with the Iguazio AI platform V3IO data layer. Before you deploy the model monitoring or serving function, you need to {py:meth}`set the credentials <mlrun.projects.MlrunProject.set_model_monitoring_credentials>`. ## Model and model monitoring endpoints Each unique combination of runtime function (a deployed Nuclio function) and model has an endpoint and a corresponding {py:meth}`model endpoint <mlrun.model_monitoring.api.get_or_create_model_endpoint>`. All model monitoring endpoints are presented in the UI with information about the actual inference, including data on the inputs, outputs, and results.The Model Endpoints tab presents the overall metrics. From there you can select an endpoint and view the Metrics, Events list, and Applications tabs. Workflow:User selects the relevant endpointWithin the endpoint, the user selectThe list of metrics, each metric is defined within an applicationThe timeframeA counter graph will be available for the timeframe, showing the number of calls to the endpoint over time. A counter with a comparison to the previous period (e.g., prior 24 hours) will be availablePer each metric selected, the user will see:A timeline graph of the metric and the threshold. The timeframe will be based on the time range they selectedA histogram showing in the X axis values-range and Y axis the number of occurrences per that value range. The timeframe will be based on the timeframe the user chose## Alerts and notificationsYou can set up {ref}`alerts` to inform you about suspected and detected issues in the model monitoring functions. And you can use {ref}`notifications` to notify about alerts. ## Common terminologyThe following terms are used in all the model monitoring pages:* **Total Variation Distance** (TVD) &mdash; The statistical difference between the actual predictions and the model's trained predictions.* **Hellinger Distance** &mdash; A type of f-divergence that quantifies the similarity between the actual predictions, and the model's trained predictions.* **Kullbackâ€“Leibler Divergence** (KLD) &mdash; The measure of how the probability distribution of actual predictions is different from the second model's trained reference probability distribution.